{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Catégorisez automatiquement des questions**\n",
    "\n",
    "### partie 4/8 : Prédiction de tags, approche supervisée + tracking mlflow\n",
    "\n",
    "#### <br> Notebook d’exploration et de pré-traitement des questions, comprenant une analyse univariée et multivariée, un nettoyage des questions, un feature engineering de type bag of words avec réduction de dimension (du vocabulaire et des tags) \n",
    "\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import librairies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Python version 3.11.5 (main, Sep 11 2023, 13:23:44) [GCC 11.2.0]\n",
      "pyLDAvis version 3.4.0\n",
      "\n",
      "Number of CPU cores: 8\n",
      "INFO: Pandarallel will run on 6 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import os, sys, random\n",
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Tuple\n",
    "from pandarallel import pandarallel\n",
    "from pprint import pprint\n",
    "import json\n",
    "import requests\n",
    "from collections import Counter\n",
    "\n",
    "# Visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from wordcloud import WordCloud\n",
    "from PIL import Image\n",
    "\n",
    "# NLP\n",
    "from bs4 import BeautifulSoup\n",
    "import re, string\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "#\n",
    "from gensim import corpora\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.matutils import corpus2dense\n",
    "from gensim.matutils import Sparse2Corpus\n",
    "from gensim.models import LdaModel, CoherenceModel\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "from gensim import similarities\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "\n",
    "#\n",
    "from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer, TransformedTargetRegressor\n",
    "from sklearn.metrics import make_scorer, PredictionErrorDisplay, r2_score\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "print('\\nPython version ' + sys.version)\n",
    "print('pyLDAvis version ' + pyLDAvis.__version__)\n",
    "\n",
    "# Modify if necessary\n",
    "num_cores = os.cpu_count()\n",
    "print(f\"\\nNumber of CPU cores: {num_cores}\")\n",
    "pandarallel.initialize(progress_bar=False, nb_workers=6)\n",
    "\n",
    "#\n",
    "import pickle\n",
    "import mlflow\n",
    "from mlflow import MlflowClient\n",
    "from mlflow.models.signature import infer_signature, ModelSignature #, Schema, ParamSchema\n",
    "from mlflow.types import Schema, ParamSchema, ParamSpec, ColSpec\n",
    "\n",
    "# os.environ['MLFLOW_TRACKING_URI'] = './'\n",
    "\n",
    "# ! REQUIRES CONSOLE COMMAND : mlflow ui\n",
    "# depuis dossier notebooks\n",
    "# at least once, to creat mlruns folder\n",
    "\n",
    "# Utilisable seulement en local...\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "client = MlflowClient(tracking_uri=\"http://127.0.0.1:5000\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_missing_values(df):\n",
    "    \"\"\"Generates a DataFrame containing the count and proportion of missing values for each feature.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): The input DataFrame to analyze.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A DataFrame with columns for the feature name, count of missing values,\n",
    "        count of non-missing values, proportion of missing values, and data type for each feature.\n",
    "    \"\"\"\n",
    "    # Count the missing values for each column\n",
    "    missing = df.isna().sum()\n",
    "\n",
    "    # Calculate the percentage of missing values\n",
    "    percent_missing = df.isna().mean() * 100\n",
    "\n",
    "    # Create a DataFrame to store the results\n",
    "    missings_df = pd.DataFrame({\n",
    "        'column_name': df.columns,\n",
    "        'missing': missing,\n",
    "        'present': df.shape[0] - missing,  # Count of non-missing values\n",
    "        'percent_missing': percent_missing.round(2),  # Rounded to 2 decimal places\n",
    "        'type': df.dtypes\n",
    "    })\n",
    "\n",
    "    # Sort the DataFrame by the count of missing values\n",
    "    missings_df.sort_values('missing', inplace=True)\n",
    "\n",
    "    return missings_df\n",
    "\n",
    "# with pd.option_context('display.max_rows', 1000):\n",
    "#   display(get_missing_values(df))\n",
    "\n",
    "\n",
    "def quick_look(df, miss=True):\n",
    "    \"\"\"\n",
    "    Display a quick overview of a DataFrame, including shape, head, tail, unique values, and duplicates.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): The input DataFrame to inspect.\n",
    "        check_missing (bool, optional): Whether to check and display missing values (default is True).\n",
    "\n",
    "    The function provides a summary of the DataFrame, including its shape, the first and last rows, the count of unique values per column, and the number of duplicates.\n",
    "    If `check_missing` is set to True, it also displays missing value information.\n",
    "    \"\"\"\n",
    "    print(f'shape : {df.shape}')\n",
    "\n",
    "    display(df.head())\n",
    "    display(df.tail())\n",
    "\n",
    "    print('uniques :')\n",
    "    display(df.nunique())\n",
    "\n",
    "    print('Doublons ? ', df.duplicated(keep='first').sum(), '\\n')\n",
    "\n",
    "    if miss:\n",
    "        display(get_missing_values(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mlflow_experiment(\n",
    "    experiment_name: str, artifact_location: str, tags: dict[str, str]\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Create a new mlflow experiment with the given name and artifact location.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    experiment_name: str\n",
    "        The name of the experiment to create.\n",
    "    artifact_location: str\n",
    "        The artifact location of the experiment to create.\n",
    "    tags: dict[str,Any]\n",
    "        The tags of the experiment to create.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    experiment_id: str\n",
    "        The id of the created experiment.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        experiment_id = mlflow.create_experiment(\n",
    "            name=experiment_name, artifact_location=artifact_location, tags=tags\n",
    "        )\n",
    "    except:\n",
    "        print(f\"Experiment {experiment_name} already exists.\")\n",
    "        experiment_id = mlflow.get_experiment_by_name(experiment_name).experiment_id\n",
    "\n",
    "    mlflow.set_experiment(experiment_name=experiment_name)\n",
    "\n",
    "    return experiment_id\n",
    "\n",
    "\n",
    "def get_mlflow_experiment(\n",
    "    experiment_id: str = None, experiment_name: str = None\n",
    ") -> mlflow.entities.Experiment:\n",
    "    \"\"\"\n",
    "    Retrieve the mlflow experiment with the given id or name.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    experiment_id: str\n",
    "        The id of the experiment to retrieve.\n",
    "    experiment_name: str\n",
    "        The name of the experiment to retrieve.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    experiment: mlflow.entities.Experiment\n",
    "        The mlflow experiment with the given id or name.\n",
    "    \"\"\"\n",
    "    if experiment_id is not None:\n",
    "        experiment = mlflow.get_experiment(experiment_id)\n",
    "    elif experiment_name is not None:\n",
    "        experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "    else:\n",
    "        raise ValueError(\"Either experiment_id or experiment_name must be provided.\")\n",
    "\n",
    "    return experiment\n",
    "\n",
    "\n",
    "def turn_str_back_into_list(df):\n",
    "    \"\"\"Correct the type change due to .csv export\"\"\"\n",
    "\n",
    "    df['title_nltk'] = df['title_nltk'].apply(ast.literal_eval)\n",
    "    df['body_nltk'] = df['body_nltk'].apply(ast.literal_eval)\n",
    "    df['title_spacy'] = df['title_spacy'].apply(ast.literal_eval)\n",
    "    df['body_spacy'] = df['body_spacy'].apply(ast.literal_eval)\n",
    "    df['all_tags'] = df['all_tags'].apply(ast.literal_eval)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again, this needs mlfow ui console command first -> unusable on remote server\n",
    "# all_experiments = client.search_experiments()\n",
    "# pprint(all_experiments)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>all_tags</th>\n",
       "      <th>title_nltk</th>\n",
       "      <th>body_nltk</th>\n",
       "      <th>title_spacy</th>\n",
       "      <th>body_spacy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42893</th>\n",
       "      <td>2017-02-23 11:34:31</td>\n",
       "      <td>Do we need clear MDC after HTTP request in Spring</td>\n",
       "      <td>According to this answer thread local variable...</td>\n",
       "      <td>[java, spring, logging, log4j, logback]</td>\n",
       "      <td>[need, mdc, request, spring]</td>\n",
       "      <td>[need, mdc, request, spring, accord, answer, t...</td>\n",
       "      <td>[need, request]</td>\n",
       "      <td>[accord, answer, thread, variable, use, clear,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42894</th>\n",
       "      <td>2011-10-13 20:57:32</td>\n",
       "      <td>How to make i18n with Handlebars.js (mustache ...</td>\n",
       "      <td>I'm currently using Handlebars.js (associated ...</td>\n",
       "      <td>[javascript, jquery, internationalization, han...</td>\n",
       "      <td>[make, i18n, handlebar, template]</td>\n",
       "      <td>[make, i18n, handlebar, template, associate, b...</td>\n",
       "      <td>[template]</td>\n",
       "      <td>[associate, web, app, client, render, issue, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42895</th>\n",
       "      <td>2012-09-06 00:16:46</td>\n",
       "      <td>How can I make R read my environmental variables?</td>\n",
       "      <td>I am running R on EC2 spot instances and I nee...</td>\n",
       "      <td>[linux, r, ubuntu, amazon-ec2, environment-var...</td>\n",
       "      <td>[make, read, variable]</td>\n",
       "      <td>[make, read, variable, run, spot, instance, ne...</td>\n",
       "      <td>[read, variable]</td>\n",
       "      <td>[run, spot, instance, need, terminate, cancel,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42896</th>\n",
       "      <td>2021-03-23 03:50:50</td>\n",
       "      <td>How to prevent react-query from fetching initi...</td>\n",
       "      <td>I'm using react-query v3.13 to fetch data from...</td>\n",
       "      <td>[javascript, reactjs, fetch, react-query, swr]</td>\n",
       "      <td>[prevent, query, fetch, enable]</td>\n",
       "      <td>[prevent, query, fetch, enable, data, want, po...</td>\n",
       "      <td>[prevent, react, query, fetch, enable]</td>\n",
       "      <td>[react, query, fetch, datum, want, api, point,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42897</th>\n",
       "      <td>2016-03-17 04:19:15</td>\n",
       "      <td>Inserting into table with an Identity column w...</td>\n",
       "      <td>I have a table A_tbl in my database. I have cr...</td>\n",
       "      <td>[sql, sql-server, database, ssms, database-rep...</td>\n",
       "      <td>[insert, table, identity, column, replication,...</td>\n",
       "      <td>[insert, table, identity, column, replication,...</td>\n",
       "      <td>[insert, table, column, replication, cause, er...</td>\n",
       "      <td>[table, database, create, trigger, capture, in...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              CreationDate                                              title  \\\n",
       "42893  2017-02-23 11:34:31  Do we need clear MDC after HTTP request in Spring   \n",
       "42894  2011-10-13 20:57:32  How to make i18n with Handlebars.js (mustache ...   \n",
       "42895  2012-09-06 00:16:46  How can I make R read my environmental variables?   \n",
       "42896  2021-03-23 03:50:50  How to prevent react-query from fetching initi...   \n",
       "42897  2016-03-17 04:19:15  Inserting into table with an Identity column w...   \n",
       "\n",
       "                                                    body  \\\n",
       "42893  According to this answer thread local variable...   \n",
       "42894  I'm currently using Handlebars.js (associated ...   \n",
       "42895  I am running R on EC2 spot instances and I nee...   \n",
       "42896  I'm using react-query v3.13 to fetch data from...   \n",
       "42897  I have a table A_tbl in my database. I have cr...   \n",
       "\n",
       "                                                all_tags  \\\n",
       "42893            [java, spring, logging, log4j, logback]   \n",
       "42894  [javascript, jquery, internationalization, han...   \n",
       "42895  [linux, r, ubuntu, amazon-ec2, environment-var...   \n",
       "42896     [javascript, reactjs, fetch, react-query, swr]   \n",
       "42897  [sql, sql-server, database, ssms, database-rep...   \n",
       "\n",
       "                                              title_nltk  \\\n",
       "42893                       [need, mdc, request, spring]   \n",
       "42894                  [make, i18n, handlebar, template]   \n",
       "42895                             [make, read, variable]   \n",
       "42896                    [prevent, query, fetch, enable]   \n",
       "42897  [insert, table, identity, column, replication,...   \n",
       "\n",
       "                                               body_nltk  \\\n",
       "42893  [need, mdc, request, spring, accord, answer, t...   \n",
       "42894  [make, i18n, handlebar, template, associate, b...   \n",
       "42895  [make, read, variable, run, spot, instance, ne...   \n",
       "42896  [prevent, query, fetch, enable, data, want, po...   \n",
       "42897  [insert, table, identity, column, replication,...   \n",
       "\n",
       "                                             title_spacy  \\\n",
       "42893                                    [need, request]   \n",
       "42894                                         [template]   \n",
       "42895                                   [read, variable]   \n",
       "42896             [prevent, react, query, fetch, enable]   \n",
       "42897  [insert, table, column, replication, cause, er...   \n",
       "\n",
       "                                              body_spacy  \n",
       "42893  [accord, answer, thread, variable, use, clear,...  \n",
       "42894  [associate, web, app, client, render, issue, w...  \n",
       "42895  [run, spot, instance, need, terminate, cancel,...  \n",
       "42896  [react, query, fetch, datum, want, api, point,...  \n",
       "42897  [table, database, create, trigger, capture, in...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4767, 8)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('./../0_data/cleaned_data/train_bow_uniques.csv', sep=',')\n",
    "test = pd.read_csv('./../0_data/cleaned_data/test_bow_uniques.csv', sep=',')\n",
    "\n",
    "turn_str_back_into_list(train)\n",
    "turn_str_back_into_list(test)\n",
    "\n",
    "display(train.tail())\n",
    "\n",
    "train.shape\n",
    "print(test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classic ML models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### knn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Often gives good results if enough data\n",
    "# Accepts basically any input, as long as it is numerical\n",
    "\n",
    "# => Perfect for testing different embeddings !\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dummy knn : il copie sur le + proche voisin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "['javascript', 'internet-explorer', 'class', 'internet-explorer-8', 'classname']\n",
      "['javascript', 'internet-explorer', 'class', 'internet-explorer-8', 'classname'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Notre baseline\n",
    "\n",
    "def predict_tags_using_dummy_knn(df, feature, target, k=1, exemple=None):\n",
    "    documents = df[feature].tolist()\n",
    "    gensim_dictionary = Dictionary(documents)\n",
    "    corpus = [gensim_dictionary.doc2bow(doc) for doc in documents]\n",
    "\n",
    "    # Convert Gensim corpus to dense matrix\n",
    "    dense_matrix = corpus2dense(corpus, num_terms=len(gensim_dictionary)).T\n",
    "\n",
    "    # Ici on ne va pas demander au knn de faire de prediction,\n",
    "    # On veut juste qu'il trouve les voisins.\n",
    "    # Mais la fonction fit a besoin de targets en param\n",
    "    target_values = df[target].values\n",
    "\n",
    "    # Initialize kNN model\n",
    "    knn_model = KNeighborsRegressor(n_neighbors=k, metric='cosine', algorithm='brute')\n",
    "    # print(knn_model.n_neighbors)\n",
    "\n",
    "    knn_model.fit(dense_matrix, target_values)\n",
    "\n",
    "    # Example query\n",
    "    query_document = exemple\n",
    "    query_bow = gensim_dictionary.doc2bow(query_document)\n",
    "    query_vector = corpus2dense([query_bow], num_terms=len(gensim_dictionary)).T\n",
    "\n",
    "    # Find nearest neighbors\n",
    "    _, indices = knn_model.kneighbors(query_vector)\n",
    "\n",
    "    # Aggregate tags from neighbors\n",
    "    neighbor_tags = [tag for i in indices.flatten() for tag in df.iloc[i][target]]\n",
    "\n",
    "    print(neighbor_tags)\n",
    "\n",
    "    # Predict tags based on most common tags among neighbors\n",
    "    predicted_tags = [tag for tag, _ in Counter(neighbor_tags).most_common(n=10)]\n",
    "    # 5 tags/question en moyenne mais on peut suggérer +\n",
    "    # ici a ameliorer\n",
    "\n",
    "    return predicted_tags, knn_model\n",
    "\n",
    "\n",
    "exemple = [\"your\", 'text', 'document', 'javascript']\n",
    "# Call the function with your DataFrame and the desired text feature and target tags\n",
    "predicted_tags, knn_test = predict_tags_using_dummy_knn(train, 'title_nltk', 'all_tags', exemple=exemple)\n",
    "print(predicted_tags, '\\n')\n",
    "\n",
    "# javascript ok\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### knn basic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c#', '.net', 'ms-word', 'openxml', 'openxml-sdk', 'javascript', 'internet-explorer', 'class', 'internet-explorer-8', 'classname', 'java', 'javascript', 'ajax', 'selenium', 'htmlunit-driver', 'c#', '.net', 'windows', 'f#', 'console', 'javascript', 'jquery', 'jquery-plugins', 'text-to-speech', 'html5-audio', 'javascript', 'html', 'css', 'text', 'truncate', 'javascript', 'jquery', 'css', 'dom', 'document', 'javascript', 'html', 'string', 'text', 'extract', 'javascript', 'dom', 'substring', 'indexof', 'getselection', 'javascript', 'html', 'function', 'text', 'onclick', 'c#', '.net', 'html', 'pdf', 'extract', 'javascript', 'jquery', 'css', 'copy', 'cut', 'javascript', 'html', 'url', 'base64', 'data-uri', 'python', 'module', 'preprocessor', 'nlp', 'stemming', 'javascript', 'php', 'jquery', 'curl', 'http-headers', 'python', 'text', 'replace', 'ms-word', 'python-docx', 'c#', 'javascript', 'html', 'http', 'dom', 'javascript', 'jquery', 'ruby-on-rails', 'tdd', 'jasmine', 'ios', 'swift', 'height', 'uilabel', 'frame', 'javascript', 'html', 'performance', 'three.js', 'webgl', 'ios', 'objective-c', 'uilabel', 'autolayout', 'uistoryboard', 'linux', 'assembly', 'x86-64', 'calling-convention', 'abi', 'javascript', 'jquery', 'html', 'css', 'bootstrap-4', 'localization', 'internationalization', 'translation', 'stripe-payments', 'stripe.net', 'html', 'spring', 'reactjs', 'spring-boot', 'thymeleaf', 'javascript', 'html', 'function', 'anchor', 'href', 'javascript', 'jquery', 'html', 'dom', 'document-ready', 'javascript', 'jquery', 'textarea', 'hyperlink', 'addition', 'html', 'sublimetext2', 'sublimetext', 'indentation', 'reformat', 'javascript', 'arrays', 'object', 'arguments', 'slice', 'javascript', 'jquery', 'ajax', 'asp.net-mvc-3', 'url', 'javascript', 'iphone', 'css', 'ios', 'uiwebview', 'javascript', 'unicode', 'diacritics', 'combining-marks', 'zalgo', 'javascript', 'firebase', 'google-cloud-platform', 'google-cloud-firestore', 'typeerror', 'javascript', 'function', 'oop', 'if-statement', 'conditional-statements', 'javascript', 'html', 'full-text-search', 'local-storage', 'client-side', 'javascript', 'node.js', 'backbone.js', 'ember.js', 'javascript-framework', 'c#', 'javascript', 'jquery', 'asp.net-mvc', 'razor', 'javascript', 'oop', 'functional-programming', 'polymorphism', 'parametric-polymorphism', 'html', 'meta-tags', 'semantics', 'semantic-web', 'semantic-markup', 'mongodb', 'mongodb-query', 'aggregation-framework', 'spring-data-mongodb', 'full-text-indexing', 'python', 'django', 'orm', 'mongodb', 'mongoengine', 'javascript', 'c#', 'asp.net-mvc', 'dictionary', 'asp.net-web-api', 'javascript', 'css', 'encapsulation', 'styling', 'web-component', 'ios', 'ocr', 'xcode4.5', 'tesseract', 'leptonica', 'javascript', 'reactjs', 'functional-programming', 'immutability', 'immutable.js', 'html', 'css', 'text', 'autocomplete', 'sublimetext', 'javascript', 'object', 'recursion', 'comparison', 'equality', 'javascript', 'arrays', 'algorithm', 'big-o', 'time-complexity', 'objective-c', 'ios', 'xcode', 'event-handling', 'uibutton']\n",
      "['javascript', 'html', 'jquery', 'css', 'c#', 'text', 'ios', 'dom', '.net', 'function'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# add grid search cv\n",
    "# add score\n",
    "\n",
    "def predict_tags_using_knn(df, feature, target, k=50, exemple=None):\n",
    "    documents = df[feature].tolist()\n",
    "    gensim_dictionary = Dictionary(documents)\n",
    "    corpus = [gensim_dictionary.doc2bow(doc) for doc in documents]\n",
    "\n",
    "    # Convert Gensim corpus to dense matrix\n",
    "    dense_matrix = corpus2dense(corpus, num_terms=len(gensim_dictionary)).T\n",
    "\n",
    "    # Ici on ne va pas demander au knn de faire de prediction,\n",
    "    # On veut juste qu'il trouve les voisins.\n",
    "    # Mais la fonction fit a besoin de targets en param\n",
    "    target_values = df[target].values\n",
    "\n",
    "    # Initialize kNN model\n",
    "    knn_model = KNeighborsRegressor(n_neighbors=k, metric='cosine', algorithm='brute')\n",
    "    knn_model.fit(dense_matrix, target_values)\n",
    "\n",
    "    # Example query\n",
    "    query_document = exemple\n",
    "    query_bow = gensim_dictionary.doc2bow(query_document)\n",
    "    query_vector = corpus2dense([query_bow], num_terms=len(gensim_dictionary)).T\n",
    "\n",
    "    # Find nearest neighbors\n",
    "    _, indices = knn_model.kneighbors(query_vector)\n",
    "\n",
    "    # Aggregate tags from neighbors\n",
    "    neighbor_tags = [tag for i in indices.flatten() for tag in df.iloc[i][target]]\n",
    "\n",
    "    print(neighbor_tags)\n",
    "\n",
    "    # Predict tags based on most common tags among neighbors\n",
    "    predicted_tags = [tag for tag, _ in Counter(neighbor_tags).most_common(n=10)]\n",
    "    # 5 tags/question en moyenne mais on peut suggérer +\n",
    "    # ici a ameliorer\n",
    "\n",
    "    # Export your model to a file\n",
    "    with open('artifacts/my_knn.pkl', 'wb') as f:\n",
    "        pickle.dump(knn_model, f)\n",
    "\n",
    "    return query_vector, predicted_tags\n",
    "\n",
    "exemple = [\"your\", 'text', 'document', 'javascript']\n",
    "query, predicted_tags = predict_tags_using_knn(train, 'title_nltk', 'all_tags', exemple=exemple)\n",
    "print(predicted_tags, '\\n')\n",
    "\n",
    "# javascript ok\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c#', '.net', 'ms-word', 'openxml', 'openxml-sdk', 'javascript', 'internet-explorer', 'class', 'internet-explorer-8', 'classname', 'java', 'javascript', 'ajax', 'selenium', 'htmlunit-driver', 'c#', '.net', 'windows', 'f#', 'console', 'javascript', 'jquery', 'jquery-plugins', 'text-to-speech', 'html5-audio', 'javascript', 'html', 'css', 'text', 'truncate', 'javascript', 'jquery', 'css', 'dom', 'document', 'javascript', 'html', 'string', 'text', 'extract', 'javascript', 'dom', 'substring', 'indexof', 'getselection', 'javascript', 'html', 'function', 'text', 'onclick', 'c#', '.net', 'html', 'pdf', 'extract', 'javascript', 'jquery', 'css', 'copy', 'cut', 'javascript', 'html', 'url', 'base64', 'data-uri', 'python', 'module', 'preprocessor', 'nlp', 'stemming', 'javascript', 'php', 'jquery', 'curl', 'http-headers', 'python', 'text', 'replace', 'ms-word', 'python-docx', 'c#', 'javascript', 'html', 'http', 'dom', 'javascript', 'jquery', 'ruby-on-rails', 'tdd', 'jasmine', 'ios', 'swift', 'height', 'uilabel', 'frame', 'javascript', 'html', 'performance', 'three.js', 'webgl', 'ios', 'objective-c', 'uilabel', 'autolayout', 'uistoryboard', 'linux', 'assembly', 'x86-64', 'calling-convention', 'abi', 'javascript', 'jquery', 'html', 'css', 'bootstrap-4', 'localization', 'internationalization', 'translation', 'stripe-payments', 'stripe.net', 'html', 'spring', 'reactjs', 'spring-boot', 'thymeleaf', 'javascript', 'html', 'function', 'anchor', 'href', 'javascript', 'jquery', 'html', 'dom', 'document-ready', 'javascript', 'jquery', 'textarea', 'hyperlink', 'addition', 'html', 'sublimetext2', 'sublimetext', 'indentation', 'reformat', 'javascript', 'arrays', 'object', 'arguments', 'slice', 'javascript', 'jquery', 'ajax', 'asp.net-mvc-3', 'url', 'javascript', 'iphone', 'css', 'ios', 'uiwebview', 'javascript', 'unicode', 'diacritics', 'combining-marks', 'zalgo', 'javascript', 'firebase', 'google-cloud-platform', 'google-cloud-firestore', 'typeerror', 'javascript', 'function', 'oop', 'if-statement', 'conditional-statements', 'javascript', 'html', 'full-text-search', 'local-storage', 'client-side', 'javascript', 'node.js', 'backbone.js', 'ember.js', 'javascript-framework', 'c#', 'javascript', 'jquery', 'asp.net-mvc', 'razor', 'javascript', 'oop', 'functional-programming', 'polymorphism', 'parametric-polymorphism', 'html', 'meta-tags', 'semantics', 'semantic-web', 'semantic-markup', 'mongodb', 'mongodb-query', 'aggregation-framework', 'spring-data-mongodb', 'full-text-indexing', 'python', 'django', 'orm', 'mongodb', 'mongoengine', 'javascript', 'c#', 'asp.net-mvc', 'dictionary', 'asp.net-web-api', 'javascript', 'css', 'encapsulation', 'styling', 'web-component', 'ios', 'ocr', 'xcode4.5', 'tesseract', 'leptonica', 'javascript', 'reactjs', 'functional-programming', 'immutability', 'immutable.js', 'html', 'css', 'text', 'autocomplete', 'sublimetext', 'javascript', 'object', 'recursion', 'comparison', 'equality', 'javascript', 'arrays', 'algorithm', 'big-o', 'time-complexity', 'objective-c', 'ios', 'xcode', 'event-handling', 'uibutton']\n",
      "['javascript', 'html', 'jquery', 'css', 'c#', 'text', 'ios', 'dom', '.net', 'function']\n"
     ]
    }
   ],
   "source": [
    "# load the model from disk using pickle\n",
    "custom_knn = pickle.load(open('artifacts/my_knn.pkl', 'rb'))\n",
    "\n",
    "_, indices = custom_knn.kneighbors(query)\n",
    "\n",
    "# Aggregate tags from neighbors\n",
    "neighbor_tags = [tag for i in indices.flatten() for tag in train.iloc[i]['all_tags']]\n",
    "print(neighbor_tags)\n",
    "\n",
    "# Predict tags based on most common tags among neighbors\n",
    "predicted_tags = [tag for tag, _ in Counter(neighbor_tags).most_common(n=10)]\n",
    "print(predicted_tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "filename = 'finalized_model.sav'\n",
    "# joblib.dump(model, filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['python', 'module', 'preprocessor', 'nlp', 'stemming', 'c#', '.net', 'ms-word', 'openxml', 'openxml-sdk', 'python', 'parsing', 'text', 'file-io', 'python-2.7', 'python-2.7', 'ubuntu', 'python-3.x', 'spatial-index', 'r-tree', 'python', 'plot', 'tree', 'data-visualization', 'visualization', 'c#', '.net', 'windows', 'f#', 'console', 'python', 'html', 'web-scraping', 'text', 'beautifulsoup', 'python', 'python-3.x', 'algorithm', 'sorting', 'mergesort', 'python', 'python-2.7', 'reflection', 'delegation', 'message-passing', 'python', 'python-3.x', 'annotations', 'lint', 'type-hinting', 'python', 'pdf', 'python-3.7', 'pypdf', 'pdf-extraction', 'python', 'selenium', 'selenium-webdriver', 'xpath', 'webdriverwait', 'python', 'macos', 'python-3.x', 'sublimetext2', 'sublimetext', 'python-3.x', 'pdf', 'text', 'extract', 'pdfminer', 'python', 'documentation', 'python-3.7', 'docstring', 'python-dataclasses', 'python', 'text', 'stemming', 'plural', 'singular', 'nlp', 'cluster-analysis', 'data-mining', 'k-means', 'text-mining', 'python', 'image', 'opencv', 'image-processing', 'computer-vision', 'python', 'regex', 'performance', 'perl', 'text-processing', 'python', 'windows', 'user-interface', 'text', 'screen', 'python', 'shell', 'encoding', 'utf-8', 'python-2.x', 'python', 'html', 'excel', 'pandas', 'dataframe', 'python', 'python-3.x', 'python-2.7', 'text-extraction', 'pdfminer', 'python', 'python-2.7', 'tkinter', 'callback', 'tkinter.text', 'python', 'utf-8', 'python-unicode', 'windows-1252', 'cp1252', 'python', 'image', 'text', 'python-imaging-library', 'bold', 'python', 'parsing', 'data-structures', 'dictionary', 'nested', 'python', 'text', 'replace', 'docx', 'zip', 'python', 'selenium', 'xpath', 'selenium-webdriver', 'webdriver', 'python', 'plugins', 'sublimetext2', 'distutils', 'python-requests', 'python', 'text', 'replace', 'ms-word', 'python-docx', 'python', 'utf-8', 'character-encoding', 'locale', 'default', 'python', 'django', 'autocomplete', 'sublimetext2', 'sublimetext', 'c#', '.net', 'html', 'pdf', 'extract', 'python', 'python-3.x', 'file', 'text', 'count', 'python', 'file', 'encryption', 'aes', 'pycrypto', 'python', 'list', 'file', 'ascii', 'newline', 'python', 'performance', 'search', 'profiling', 'large-files', 'python', 'sql-server', 'sql-server-2008', 'python-2.7', 'pymssql', 'html', 'sublimetext2', 'sublimetext', 'indentation', 'reformat', 'mongodb', 'mongodb-query', 'aggregation-framework', 'spring-data-mongodb', 'full-text-indexing', 'python', 'excel', 'com', 'pywin32', 'win32com', 'python', 'loops', 'if-statement', 'break', 'conditional-operator', 'java', 'python', 'jython', 'pip', 'easy-install', 'python', 'unit-testing', 'testing', 'mocking', 'patch', 'python', 'loops', 'for-loop', 'infinite-loop', 'infinite', 'python-2.7', 'exception', 'python-3.x', 'traceback', 'raise', 'python', 'debugging', 'multiprocessing', 'pycharm', 'winpdb', 'python', 'packaging', 'remote-access', 'download', 'software-update', 'python', 'constructor', 'destructor', 'with-statement', 'contextmanager']\n",
      "['python', 'text', 'python-3.x', 'python-2.7', 'html', 'sublimetext2', 'c#', '.net', 'pdf', 'sublimetext'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "exemple = [\"your\", 'text', 'document', 'python']\n",
    "# Call the function with your DataFrame and the desired text feature and target tags\n",
    "predicted_tags = predict_tags_using_knn(train, 'title_nltk', 'all_tags', exemple=exemple)\n",
    "print(predicted_tags, '\\n')\n",
    "\n",
    "# python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['find', 'class', 'com', 'google', 'firebase', 'provider']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['java', 'spring', 'rest', 'gradle', 'spring-boot', 'java', 'android', 'firebase', 'gradle', 'android-gradle-plugin', 'android', 'android-studio', 'firebase', 'android-gradle-plugin', 'google-play-services', 'android', 'android-intent', 'arraylist', 'unmarshalling', 'parcelable', 'php', 'class', 'laravel', 'alias', 'autoloader', 'php', 'sql', 'laravel', 'laravel-5', 'laravel-artisan', 'java', 'spring', 'spring-boot', 'spring-security', 'spring-security-oauth2', 'java', 'maven', 'maven-2', 'maven-3', 'protocol-buffers', 'android', 'google-maps', 'dictionary', 'android-mapview', 'inflate', 'android', 'android-studio', 'flutter', 'sdk', 'android-sdk-manager', 'java', 'spring', 'junit', 'spring-boot', 'spring-data', 'php', 'laravel', 'https', 'laravel-valet', 'valet', 'spring', 'maven', 'spring-mvc', 'spring-boot', 'spring-profiles', 'json', 'angular', 'typescript', 'jwt', 'guard', 'c#', '.net', 'visual-studio-2012', 'compression', 'zip', 'c#', 'asp.net', 'google-api', 'google-oauth', 'google-api-dotnet-client', 'ios', 'ipad', 'frameworks', 'header', 'gpuimage', 'android', 'firebase', 'gradle', 'android-gradle-plugin', 'crashlytics', 'java', 'jar', 'maven-2', 'manifest', 'program-entry-point', 'gcc', 'ubuntu', 'linker', 'shared-libraries', 'ld', 'java', 'interface', 'go', 'static-methods', 'abstract', 'javascript', 'node.js', 'typescript', 'nestjs', 'class-validator', 'c#', 'android', 'firebase', 'unity-game-engine', 'firebase-authentication', 'c#', '.net', 'visual-studio', 'json.net', 'nuget', 'android', 'firebase', 'android-studio', 'android-gradle-plugin', 'jcenter', 'iphone', 'objective-c', 'ios', 'xcode4.3', 'cocoapods', 'javascript', 'node.js', 'mongodb', 'mongoose', 'mongodb-query', 'database', 'security', 'firebase', 'firebase-authentication', 'firebase-security', 'php', 'laravel', 'amazon-web-services', 'laravel-5', 'laravelcollective', 'c#', '.net', 'web-config', 'class-library', 'configurationmanager', 'android', 'unity-game-engine', 'abi', 'arcore', 'unsatisfiedlinkerror', 'javascript', 'android', 'reactjs', 'react-native', 'gradle', 'python', 'tensorflow', 'keras', 'transfer-learning', 'vgg-net', 'angularjs', 'routes', 'angular-ui-router', 'single-page-application', 'angularjs-routing', 'java', 'linux', 'ubuntu', 'netbeans', 'command-line', 'firebase', 'flutter', 'dart', 'firebase-authentication', 'google-authentication', 'java', 'android', 'android-studio', 'gradle', 'build', 'c++', 'ubuntu', 'sdl', 'sdl-2', 'sdl-image', 'google-maps', 'angular', 'typescript', 'angular-cli', 'angular2-google-maps', 'python', 'class', 'inheritance', 'python-3.x', 'language-design', 'java', 'android', 'design-patterns', 'inheritance', 'parcelable', 'javascript', 'node.js', 'angular', 'typescript', 'angular7', 'c++', 'gcc', 'vtable', 'virtual-inheritance', 'vtt', 'javascript', 'firebase', 'google-drive-api', 'firebase-authentication', 'adobe-indesign', 'ios', 'objective-c', 'xcode', 'storyboard', 'xib', 'java', 'maven', 'build', 'interop', 'kotlin', 'c++', 'c++11', 'bit-fields', 'bitmask', 'enum-class', 'java', 'json', 'rest', 'jersey', 'jax-rs', 'android', 'firebase', 'flutter', 'google-play-services', 'flutter-dependencies', 'android', 'android-intent', 'classnotfoundexception', 'unmarshalling', 'parcel']\n",
      "['android', 'java', 'firebase', 'gradle', 'c#', 'javascript', 'spring', 'spring-boot', 'android-gradle-plugin', 'android-studio'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "exemple1 = test['title_nltk'][0]\n",
    "print(exemple1)\n",
    "# Call the function with your DataFrame and the desired text feature and target tags\n",
    "predicted_tags1 = predict_tags_using_knn(train, 'title_nltk', 'all_tags', exemple=exemple1)\n",
    "print(predicted_tags1, '\\n')\n",
    "\n",
    "# firebase peut etre predit\n",
    "# grand succes !\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['get', 'lang', 'noclassdeffounderror', 'scala', 'run', 'code']\n",
      "['c#', '.net', 'wpf', 'code-behind', 'itemspanel', 'java', 'gradle', 'spring-boot', 'jar', 'build.gradle', 'reactjs', 'authentication', 'google-authentication', 'google-api-js-client', 'googleauthr', 'c', 'gcc', 'types', 'openmp', 'typeof', 'php', 'mysql', 'laravel', 'ubuntu', 'server', 'iphone', 'ios', 'xamarin.ios', 'http-response-codes', 'nsurlconnectiondelegate', 'c++', 'python', 'ctypes', 'cython', 'boost-python', 'scala', 'maven', 'apache-spark', 'noclassdeffounderror', 'spark-streaming', 'macos', 'shell', 'scala', 'terminal', 'installation', 'javascript', 'vue.js', 'visual-studio-code', 'nuxt.js', 'prettier', 'c#', 'multithreading', 'winforms', 'backgroundworker', 'infinite-loop', 'asp.net-core', 'oauth', 'identityserver4', 'openid-connect', 'asp.net-core-3.0', 'c++', 'c', 'cuda', 'parallel-processing', 'gpu', 'javascript', 'node.js', 'express', 'firebase', 'firebase-realtime-database', 'python', 'selenium', 'http', 'selenium-webdriver', 'ui-automation', 'c++', 'c', 'types', 'int64', 'long-long', 'javascript', 'angularjs', 'promise', 'deferred', 'finally', 'javascript', 'typescript', 'visual-studio-code', 'vscode-extensions', 'file-properties', 'c#', 'sql-server', 'asp.net-mvc', 'entity-framework', 'asp.net-mvc-4', 'c', 'assembly', 'x86', 'x86-64', 'shellcode', 'c', 'assembly', 'x86', 'reverse-engineering', 'decompiling', 'unix', 'ubuntu', 'command-line', 'go', 'terminal', 'c', 'linux', 'security', 'exploit', 'secure-coding', 'javascript', 'firebase', 'react-native', 'mocking', 'jestjs', 'stack-trace', 'glibc', 'sigabrt', 'segmentation-fault', 'backtrace', 'java', 'rest', 'exception', 'jersey', 'provider', 'javascript', 'python', 'google-chrome', 'sandbox', 'brython', 'java', 'selenium', 'testing', 'selenium-webdriver', 'selenium-chromedriver', 'python', 'python-2.7', 'stdout', 'stderr', 'os.system', 'java', 'python', 'apache-spark', 'directed-acyclic-graphs', 'airflow', 'scala', 'random', 'collections', 'set', 'scala-collections', 'flash', 'apache-flex', 'debugging', 'air', 'flash-builder', 'javascript', 'html', 'ajax', 'url', 'xmlhttprequest', 'iphone', 'xcode', 'ios-simulator', 'ios5', 'freeze', 'android', 'google-maps', 'google-maps-android-api-2', 'latitude-longitude', 'google-places-api', 'c++', 'performance', 'assembly', 'optimization', 'x86', 'git', 'jenkins', 'groovy', 'jenkins-plugins', 'jenkins-pipeline', 'linux', 'bash', 'shell', 'terminal', 'paste', 'android', 'android-emulator', 'android-service', 'monitoring', 'monitor', 'android', 'enums', 'android-custom-view', 'attr', 'custom-view', 'android', 'retrofit', 'rx-java', 'android-networking', 'rx-android', 'java', 'jvm', 'compatibility', 'java-7', 'java-8', 'php', 'templates', 'model-view-controller', 'file-io', 'eval', 'c#', 'android', 'xamarin', 'xamarin.android', 'android-runonuithread', 'python', 'unicode', 'encoding', 'utf-8', 'character-codes', 'javascript', 'vue.js', 'model-view-controller', 'vuejs2', 'vuejs3', 'ios', 'swift', 'ios-simulator', 'xcode6', 'xcode6-beta6', 'linux', 'bash', 'shell', 'unix', 'sudo', 'python', 'pandas', 'visual-studio-code', 'jupyter-notebook', 'tqdm', 'java', 'file', 'jar', 'io', 'extract']\n",
      "['javascript', 'python', 'java', 'c', 'android', 'c#', 'c++', 'scala', 'shell', 'terminal'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "exemple2 = test['title_nltk'][1]\n",
    "print(exemple2)\n",
    "# Call the function with your DataFrame and the desired text feature and target tags\n",
    "predicted_tags2 = predict_tags_using_knn(train, 'title_nltk', 'all_tags', exemple=exemple2)\n",
    "print(predicted_tags2, '\\n')\n",
    "\n",
    "# scala ok\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notre objectif de prédiction de tags ressemble a un pb de classification multi-label,\n",
    "# où la matrice de confusion est extrêmement déséquilibrée :\n",
    "# 5 tags sont prédits positifs, contre environ 250 000 tags (si on travaille sur all_tags)\n",
    "# predits negatifs. Autrement dit :\n",
    "\n",
    "# On peut utiliser la precision pour évaluer notre modèle. C'est même exactement l'outil qu'il nous faut :\n",
    "# \"précision = la proportion de prédictions correctes parmi les points que l’on a prédits positifs.\"\n",
    "# En + c de loin le plus léger en ressources, puisqu'il ne s'occupe que des 5 tags prédits.\n",
    "\n",
    "# En revanche je pense que le recall n'a pas vraiment de sens ici, il sera \"écrasé\" par\n",
    "# le nombre de tags predits negatifs, sa valeur sera tjs très proche de zero.\n",
    "# (même remarque pour la spécificité et l'accuracy)\n",
    "# Et sans recall, pas de f1 score.\n",
    "# à vérifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### precision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0\n"
     ]
    }
   ],
   "source": [
    "# pourquoi on ne peut pas utiliser le score precision sckikit ici :\n",
    "from sklearn.metrics import precision_score as p_score\n",
    "\n",
    "# Assuming y_true is the ground truth (real tags) and y_pred is the predicted tags\n",
    "precision = p_score(['ok', 'ko'], ['ko', 'ok'], average='micro')  # You can use 'micro', 'macro', or 'weighted' depending on your use case\n",
    "print(f'Precision: {precision}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def precision_topics(real_tags:list, predicted_tags:list): # pour comparer 2 listes\n",
    "    # precision = TP / (TP + FP)\n",
    "    tp = 0\n",
    "    for predicted_tag in predicted_tags:\n",
    "        if predicted_tag in real_tags:\n",
    "            tp += 1\n",
    "\n",
    "    fp = len(predicted_tags) - tp\n",
    "    precision = tp/(tp + fp)\n",
    "    # <=> precision = tp/len(predicted_tags)\n",
    "\n",
    "    return precision\n",
    "\n",
    "\n",
    "print(precision_topics(exemple1, predicted_tags1))\n",
    "precision_topics(exemple2, predicted_tags2)\n",
    "\n",
    "# ok\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_score(y_true, y_pred): # pour comparer 2 df ou 2 matrices de mm shape[0]\n",
    "    precision = 0\n",
    "    for i in range(0, len(y_pred)):\n",
    "        precision += precision_topics(y_true[i], y_pred[i])\n",
    "    precision_moyenne = precision / len(y_pred)\n",
    "\n",
    "    return precision_moyenne\n",
    "\n",
    "\n",
    "# pour la gridsearchcv\n",
    "custom_precision_scorer = make_scorer(precision_score, greater_is_better=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### recall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_topics(all_tags: list, predicted_tags: list):\n",
    "    # recall = TP / (TP + FN)\n",
    "    tp = 0\n",
    "    fn = 0\n",
    "    for real_tag in all_tags:\n",
    "        if real_tag in predicted_tags:\n",
    "            tp += 1\n",
    "        else:\n",
    "            fn += 1\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "\n",
    "    return recall\n",
    "\n",
    "\n",
    "# insister ds la doctype : y_all = all tags ici, != y_true (5-6 tags max)\n",
    "def recall_score(y_all, y_pred): # pour comparer 2 df ou 2 matrices de mm shape[0]\n",
    "    recall = 0\n",
    "    for i in range(0, len(y_pred)):\n",
    "        recall += recall_topics(y_all, y_pred[i]) # ca risque d'etre long a calculer\n",
    "    recall_moyen = recall / len(y_pred)\n",
    "\n",
    "    return recall_moyen\n",
    "\n",
    "custom_recall_scorer = make_scorer(recall_score, greater_is_better=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### f1 score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_topics(real_tags: list, predicted_tags: list, all_tags:list):\n",
    "    precision = precision_score(real_tags, predicted_tags)\n",
    "    recall = recall_topics(all_tags, predicted_tags)\n",
    "\n",
    "    # F1 score = 2 * (precision * recall) / (precision + recall)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    return f1\n",
    "\n",
    "\n",
    "def f1_score(y_true, y_pred, y_all):\n",
    "    f1_score = 0\n",
    "    for i in range(0, len(y_pred)):\n",
    "        score += f1_topics(y_true[i], y_pred[i], y_all)\n",
    "    score_moyen = score / len(y_pred)\n",
    "\n",
    "    return score_moyen\n",
    "\n",
    "\n",
    "custom_f1_scorer = make_scorer(f1_score, greater_is_better=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_topics(real_tags: list, predicted_tags: list, all_tags:list):\n",
    "    # accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "    tp = sum(1 for tag in predicted_tags if tag in real_tags)\n",
    "    tn = sum(1 for tag in all_tags if (tag not in predicted_tags) and (tag not in real_tags) )\n",
    "    fp = sum(1 for tag in predicted_tags if tag not in real_tags)\n",
    "    fn = sum(1 for tag in all_tags if (tag not in predicted_tags) and (tag in real_tags))\n",
    "\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn) if (tp + tn + fp + fn) > 0 else 0\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def accuracy_score(y_true, y_pred, y_all):\n",
    "    score = 0\n",
    "    for i in range(0, len(y_pred)):\n",
    "        score += accuracy_topics(y_true[i], y_pred[i], y_all)\n",
    "    score_moyen = score / len(y_pred)\n",
    "\n",
    "    return score_moyen\n",
    "\n",
    "\n",
    "custom_accuracy_scorer = make_scorer(accuracy_score, greater_is_better=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### jaccard similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utilisé en partie 3 pour évaluer la similarité des topics obtenus / la lda\n",
    "# ici pour comparer topics reels et topics predits.\n",
    "# devrait etre proportionnel a la precision non ?\n",
    "# st ts les 2 proportionnels au nb de tp (true positifs)\n",
    "\n",
    "def jaccard_similarity(topic1, topic2):\n",
    "    set1 = set(topic1)\n",
    "    set2 = set(topic2)\n",
    "    return len(set1.intersection(set2)) / len(set1.union(set2))\n",
    "\n",
    "\n",
    "def jaccard_score(y_true, y_pred): # pour comparer 2 df ou 2 matrices de mm shape[0]\n",
    "    jacc = 0\n",
    "    for i in range(0, len(y_pred)):\n",
    "        jacc += jaccard_similarity(y_true[i], y_pred[i])\n",
    "    jacc_moyen = jacc / len(y_pred)\n",
    "\n",
    "    return jacc_moyen\n",
    "\n",
    "\n",
    "# pour la gridsearchcv\n",
    "custom_jacc_scorer = make_scorer(jaccard_score, greater_is_better=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8513\n",
      "42898\n",
      "(42898, 8513) \n",
      "\n",
      "array([[1., 1., 1., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)\n",
      "\n",
      "\n",
      "doc 2500 : ['let', 'support', 'element', 'try', 'get', 'application', 'run', 'stop', 'template', 'error', 'thead', 'tbody', 'row', 'index', 'datepicker', 'sec', 'html', 'syntaxerror', 'compiler', 'parse', 'set', 'foreach', 'figure', 'need', 'follow', 'topic', 'issue', 'state', 'bootstrap', 'beta', 'doesnt', 'work', 'http', 'github', 'com', 'software', 'help', 'appreciate']\n",
      "real tags : ['html', 'angular', 'npm', 'frontend', 'ngx-bootstrap']\n",
      "predicted : ['git', 'github', 'nginx', 'ssh', 'vps']\n",
      "0.0 \n",
      "\n",
      "doc 2501 : ['java', 'string', 'modify', 'search', 'representation', 'get', 'material', 'look', 'com', 'cpp', 'misc', 'multi', 'article', 'php', 'say', 'text', 'support', 'modification', 'serialization', 'wikipedia', 'org', 'wiki', 'data', 'byte', 'char', 'memory', 'please', 'let', 'know', 'one']\n",
      "real tags : ['java', 'string', 'encoding', 'utf-8', 'utf-16']\n",
      "predicted : ['http', 'https', 'http2', 'web-development-server', 'http-1.1']\n",
      "0.0 \n",
      "\n",
      "doc 2502 : ['test', 'website', 'end', 'develop', 'php', 'service', 'production', 'performance', 'load', 'side', 'client', 'want', 'know', 'response', 'time', 'object', 'etc', 'apache', 'web', 'server', 'request', 'handle', 'start', 'source', 'tool', 'platform', 'purpose', 'user', 'example', 'check', 'metric']\n",
      "real tags : ['php', 'apache', 'performance', 'performance-testing', 'load-testing']\n",
      "predicted : ['testing', 'performance', 'load-testing', 'angular', 'performance-testing']\n",
      "0.6 \n",
      "\n",
      "doc 2503 : ['way', 'convert', 'recommend', 'pdf', 'attach', 'email', 'prefer', 'store', 'memory', 'byte', 'disk', 'thanks', 'help']\n",
      "real tags : ['c#', '.net', 'wpf', 'pdf', 'flowdocument']\n",
      "predicted : ['ios', 'iphone', 'pdf', 'ios4', 'accessibility']\n",
      "0.2 \n",
      "\n",
      "doc 2504 : ['webstorm', 'resolve', 'directory', 'start', 'bug', 'turn', 'fix', 'feature', 'parser', 'attempt', 'string', 'suppose', 'reference', 'file', 'project', 'example', 'end', 'code', 'app', 'server', 'serve', 'root', 'web', 'context', 'side', 'behavior', 'impact', 'template', 'route', 'imagine', 'way', 'change', 'treat', 'disable', 'try', 'inspector', 'find', 'option', 'help', 'appreciate', 'thanks']\n",
      "real tags : ['javascript', 'html', 'angularjs', 'ide', 'webstorm']\n",
      "predicted : ['reactjs', 'linux', 'ssh', 'archive', 'tar']\n",
      "0.0 \n",
      "\n",
      "doc 2505 : ['swift', 'url', 'default', 'browser', 'open', 'system', 'language', 'osx', 'platform', 'find', 'lot', 'uiapplication', 'sharedapplication', 'string', 'work', 'launch', 'service', 'example', 'deprecate']\n",
      "real tags : ['xcode', 'macos', 'swift', 'nsurl', 'openurl']\n",
      "predicted : ['android', 'ios', 'hyperlink', 'android-intent', '.net']\n",
      "0.0 \n",
      "\n",
      "doc 2506 : ['style', 'javafx', 'menu', 'item', 'get', 'menubar', 'setup', 'follow', 'vbox', 'text', 'menuitem', 'project', 'quit', 'produce', 'file', 'bar', 'show', 'label', 'activate', 'display', 'try', 'treat', 'contextmenu', 'context', 'color', 'red', 'anything', 'surprise', 'button', 'change', 'select', 'call', 'seem', 'exist', 'question', 'container', 'hold', 'clarification', 'help', 'clarify', 'element', 'look', 'add', 'image', 'outline', 'component', 'wish']\n",
      "real tags : ['css', 'javafx', 'menu', 'javafx-2', 'javafx-8']\n",
      "predicted : ['objective-c', 'ios', 'xcode', 'iphone', 'swift']\n",
      "0.0 \n",
      "\n",
      "doc 2507 : ['download', 'image', 'azure', 'machine', 'upload', 'account', 'credential', 'know', 'wget', 'help', 'occur', 'error', 'code', 'message', 'specify', 'resource', 'exist', 'requestid', 'time', 'idea', 'try', 'migrate', 'get', 'trouble', 'work']\n",
      "real tags : ['powershell', 'azure', 'cloud', 'virtual-machine', 'azure-storage']\n",
      "predicted : ['python', 'download', 'amazon-web-services', 'amazon-s3', 'google-drive-api']\n",
      "0.0 \n",
      "\n",
      "doc 2508 : ['protocol', 'buffer', 'import', 'recognize', 'intellij', 'attempt', 'message', 'try', 'protobuf', 'code', 'generate', 'java', 'compiles', 'run', 'expect', 'idea', 'edition', 'editor', 'plugin', 'april', 'gradle', 'build', 'file', 'look', 'plugins', 'com', 'google', 'version', 'group', 'tech', 'sourcecompatibility', 'def', 'repositories', 'test', 'dependency', 'implementation', 'grpc', 'org', 'apache', 'tomcat', 'annotation', 'api', 'advance', 'need', 'jsonformat', 'shade', 'testimplementation', 'compile', 'name', 'testcompile', 'junit', 'jupiter', 'engine', 'mockito', 'core', 'artifact', 'gen', 'ides', 'eclipse', 'netbeans', 'sourcesets', 'srcdirs', 'source', 'proto', 'task', 'type', 'service', 'server', 'project', 'builddir', 'tmp', 'client', 'time', 'revision', 'kotlin', 'dsl', 'groovy', 'july', 'jvm', 'oracle', 'corporation', 'mac', 'x86_64', 'example', 'fail', 'package', 'option', 'describe', 'column', 'metadata', 'string', 'int32', 'size', 'enum', 'integer', 'float', 'text', 'skip', 'sit', 'system', 'src']\n",
      "real tags : ['java', 'gradle', 'intellij-idea', 'protocol-buffers', 'grpc']\n",
      "predicted : ['java', 'intellij-idea', 'junit', 'cucumber', 'cucumber-junit']\n",
      "0.4 \n",
      "\n",
      "doc 2509 : ['execute', 'foreach', 'window', 'tool', 'probe', 'state', 'debug', 'process', 'learn', 'question', 'mark', 'bit', 'show', 'post', 'know', 'query', 'include', 'expression', 'fail', 'statement', 'thing', 'get', 'error', 'contain', 'term', 'gallery', 'say', 'work', 'programmer', 'leave', 'time', 'look', 'something']\n",
      "real tags : ['c#', 'linq', 'visual-studio', 'lambda', 'immediate-window']\n",
      "predicted : ['c', 'windows', 'segmentation-fault', 'malloc', 'porting']\n",
      "0.0 \n",
      "\n",
      "doc 2510 : ['distinct', 'function', 'postgres', 'problem', 'schema', 'photo', 'tag', 'comment', 'query', 'want', 'multiply', 'row', 'get', 'select', 'name', 'leave', 'join', 'thing', 'mean', 'group', 'copy', 'array', 'city', 'make', 'json', 'like', 'sql']\n",
      "real tags : ['sql', 'json', 'postgresql', 'distinct', 'aggregate-functions']\n",
      "predicted : ['sql', 'postgresql', 'mysql', 'select', 'duplicates']\n",
      "0.4 \n",
      "\n",
      "precision moyenne = 0.0945165945165945\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0945165945165945"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add grid search cv\n",
    "# add recall, f1 score ?\n",
    "\n",
    "def predict_tags_using_knn(train_df=train, feature='body_nltk', target='all_tags', test_df=test, k=5, n=5,\n",
    "                           scorer=precision_score):\n",
    "    # 1 PREPROCESSING\n",
    "    documents = train_df[feature].tolist()\n",
    "    gensim_dictionary = Dictionary(documents)\n",
    "    print(len(gensim_dictionary))\n",
    "    corpus = [gensim_dictionary.doc2bow(doc) for doc in documents]\n",
    "    print(len(corpus))\n",
    "    # taille corpus ?\n",
    "\n",
    "    # Convert Gensim corpus to dense matrix\n",
    "    dense_matrix = corpus2dense(corpus, num_terms=len(gensim_dictionary)).T\n",
    "    # taille matrice ? afficher\n",
    "    print(dense_matrix.shape, '\\n')\n",
    "    # pas tres dense ici, c notre bow donc tres sparse en fait\n",
    "    # curieux d'appeler \"corpus2dense()\" une fonction qui retourne une matrice sparse\n",
    "    pprint(dense_matrix[:10]) # vraiment tres dense, quasiment que des 0 ! Bref\n",
    "    print('\\n')\n",
    "\n",
    "    # Ici on ne va pas demander au knn de faire de prediction,\n",
    "    # On veut juste qu'il trouve les voisins.\n",
    "    # Mais la fonction fit a besoin de targets en param\n",
    "    target_values = train_df[target].values\n",
    "\n",
    "    # 2 MODEL TRAINING\n",
    "    knn_model = KNeighborsRegressor(n_neighbors=k)\n",
    "    knn_model.fit(dense_matrix, target_values)\n",
    "\n",
    "    # 3 PREDICTION\n",
    "    # Predictions completes en 1h ou 2\n",
    "    # optimiser avec pandarallel ?\n",
    "    # use a sample en attendant\n",
    "    predictions=[]\n",
    "    min_range=2500\n",
    "    max_range=2511 # test.shape[0]=4767\n",
    "    for i in range(min_range, max_range):\n",
    "        query_document = test_df[feature][i]\n",
    "        print(f'doc {i} : {query_document}')\n",
    "        print(f'real tags : {test[target][i]}')\n",
    "        query_bow = gensim_dictionary.doc2bow(query_document)\n",
    "        query_vector = corpus2dense([query_bow], num_terms=len(gensim_dictionary)).T\n",
    "\n",
    "        # Find nearest neighbors\n",
    "        _, indices = knn_model.kneighbors(query_vector)\n",
    "\n",
    "        # Aggregate tags from neighbors\n",
    "        neighbor_tags = [tag for i in indices.flatten() for tag in train_df.iloc[i][target]]\n",
    "\n",
    "        # Predict tags based on most common tags among neighbors\n",
    "        predicted_tags = [tag for tag, _ in Counter(neighbor_tags).most_common(n=n)]\n",
    "        # 5 tags/question en moyenne mais on peut suggérer +\n",
    "        predictions.append(predicted_tags)\n",
    "        print(f'predicted : {predicted_tags}')\n",
    "        print(precision_topics(test_df[target][i], predicted_tags), '\\n')\n",
    "\n",
    "    true_tags = [tags for tags in test_df[target][min_range:max_range]]\n",
    "\n",
    "    # mean_precision = precision_score(true_tags, predictions)\n",
    "    mean_precision = scorer(true_tags, predictions)\n",
    "\n",
    "    print(f'precision moyenne = {mean_precision}')\n",
    "\n",
    "    return mean_precision\n",
    "\n",
    "\n",
    "# Call the function with your DataFrame and the desired text feature and target tags\n",
    "predict_tags_using_knn(scorer=jaccard_score)\n",
    "\n",
    "# 0.34 de precision ?? c enorme !\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=45 \n",
      "\n",
      "\n",
      "\n",
      "k=46 \n",
      "\n",
      "\n",
      "\n",
      "k=47 \n",
      "\n",
      "\n",
      "\n",
      "k=48 \n",
      "\n",
      "\n",
      "\n",
      "k=49 \n",
      "\n",
      "\n",
      "\n",
      "k=50 \n",
      "\n",
      "\n",
      "\n",
      "k=51 \n",
      "\n",
      "\n",
      "\n",
      "k=52 \n",
      "\n",
      "\n",
      "\n",
      "k=53 \n",
      "\n",
      "\n",
      "\n",
      "k=54 \n",
      "\n",
      "\n",
      "\n",
      "k=55 \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "precision = []\n",
    "for k in range(45, 50): # pour un classifieur binaire il faut k impair, mais ici comme on veut\n",
    "    # encore que ?? les nb impairs semblent obtenir de meilleurs resultats\n",
    "    print(f'k={k}', '\\n')\n",
    "    # precision.append((k, predict_tags_using_knn(k=k)))\n",
    "\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  meilleur score = 0\n"
     ]
    }
   ],
   "source": [
    "# body\n",
    "# 0.33 pour k=5\n",
    "# 0.37 pour k proche de 50 !!\n",
    "\n",
    "record_max = 0\n",
    "for k, result in precision:\n",
    "    print(f'For {k} neighbors : precision moyenne = {result}')\n",
    "    if result > record_max:\n",
    "        record_max = result\n",
    "\n",
    "print('\\n', f' meilleur score = {record_max}')\n",
    "\n",
    "# sur 'title_nltk' :\n",
    "# best : 0.29 pour k=47-48\n",
    "# = 1 quart des tags predits correctement\n",
    "# pas mal !\n",
    "\n",
    "# mieux sur body que sur title (heureusement !)\n",
    "\n",
    "# tester predire seulement 3 ou 4 tags ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=50 \n",
      "\n",
      "\n",
      "\n",
      "k=60 \n",
      "\n",
      "\n",
      "\n",
      "k=70 \n",
      "\n",
      "\n",
      "\n",
      "k=80 \n",
      "\n",
      "\n",
      "\n",
      "k=90 \n",
      "\n",
      "\n",
      "\n",
      "k=100 \n",
      "\n",
      "\n",
      "\n",
      "k=110 \n",
      "\n",
      "\n",
      "\n",
      "k=120 \n",
      "\n",
      "\n",
      "\n",
      "k=130 \n",
      "\n",
      "\n",
      "\n",
      "k=140 \n",
      "\n",
      "\n",
      "\n",
      "k=150 \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "precision4 = []\n",
    "precision3 = []\n",
    "for k in range(50, 151, 10): # pour un classifieur binaire il faut k impair, mais ici comme on veut\n",
    "    # encore que ?? les nb impairs semblent obtenir de meilleurs resultats\n",
    "    print(f'k={k}', '\\n')\n",
    "    # precision4.append((k, predict_tags_using_knn(k=k, n=4)))\n",
    "    # precision3.append((k, predict_tags_using_knn(k=k, n=3)))\n",
    "\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  meilleur score (4 tags predits) = 0\n",
      "\n",
      "  meilleur score (3 tags predits) = 0\n"
     ]
    }
   ],
   "source": [
    "# pas touche !\n",
    "# > 0.5 !!\n",
    "\n",
    "# factoriser\n",
    "score_max4 = 0\n",
    "for k, result in precision4:\n",
    "    print(f'For {k} neighbors : precision moyenne = {result}')\n",
    "    if result > score_max4:\n",
    "        score_max4 = result\n",
    "\n",
    "score_max3 = 0\n",
    "for k, result in precision3:\n",
    "    print(f'For {k} neighbors : precision moyenne = {result}')\n",
    "    if result > score_max3:\n",
    "        score_max3 = result\n",
    "\n",
    "print('\\n', f' meilleur score (4 tags predits) = {score_max4}')\n",
    "print('\\n', f' meilleur score (3 tags predits) = {score_max3}')\n",
    "\n",
    "# 26\n",
    "\n",
    "# tester k > 100 ?\n",
    "# test en reduisant le corpus de tags ? ou pas (conserver la richesse du corpus ?)\n",
    "# tester ce qui prend le + de tps (1 predict = environ 10 secondes, trop long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  meilleur score (4 tags predits) = 0\n",
      "\n",
      "  meilleur score (3 tags predits) = 0\n"
     ]
    }
   ],
   "source": [
    "# yes\n",
    "\n",
    "score_max4 = 0\n",
    "for k, result in precision4:\n",
    "    print(f'For {k} neighbors : precision moyenne = {result}')\n",
    "    if result > score_max4:\n",
    "        score_max4 = result\n",
    "\n",
    "\n",
    "score_max3 = 0\n",
    "for k, result in precision3:\n",
    "    print(f'For {k} neighbors : precision moyenne = {result}')\n",
    "    if result > score_max3:\n",
    "        score_max3 = result\n",
    "\n",
    "\n",
    "print('\\n', f' meilleur score (4 tags predits) = {score_max4}')\n",
    "print('\\n', f' meilleur score (3 tags predits) = {score_max3}')\n",
    "\n",
    "# near 60\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### gridsearch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nous avons besoin de transformer la target pdt le preprocessing (-> bow)\n",
    "# Or impossible avec un pipeline sckikit, qui passe la target sans la toucher.\n",
    "# TransformedTargetRegressor est un modele wrapper, utilisé apres le pipeline.\n",
    "# trouvé qq \"solutions\" + ou - elegantes, mais rien de compatible avec mlflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_list_into_bow(X):\n",
    "    documents = X.tolist()\n",
    "    # print(documents)\n",
    "    gensim_dictionary = Dictionary(documents)\n",
    "    corpus = [gensim_dictionary.doc2bow(doc) for doc in documents]\n",
    "\n",
    "    # Convert Gensim corpus to dense matrix\n",
    "    bow_matrix = corpus2dense(corpus, num_terms=len(gensim_dictionary)).T\n",
    "\n",
    "    return bow_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Best Hyperparameters: {'knn_regressor__n_neighbors': 1, 'knn_regressor__weights': 'uniform'}\n",
      "Cross-Validation Scores:\n",
      "{'fit_time': array([ 8.82941604,  9.36467361,  9.60334134,  9.22602916, 10.04538989]),\n",
      " 'score_time': array([41.47158408, 40.2256763 , 53.41726947, 39.55306458, 39.21628881]),\n",
      " 'test_score': array([0.13908438, 0.12855223, 0.1379184 , 0.11534947, 0.13819538])}\n",
      "Split 1 : precision = 0.13908437598610943\n",
      "Split 2 : precision = 0.12855223198879706\n",
      "Split 3 : precision = 0.1379184008530252\n",
      "Split 4 : precision = 0.11534946795589829\n",
      "Split 5 : precision = 0.13819538365044592\n"
     ]
    }
   ],
   "source": [
    "# test sans le preprocessor\n",
    "# obligé de transformer la target mm si on ne s'sn sert pas vraiment, car grid_search.fit()\n",
    "# n'accepte que des valeurs numériques.\n",
    "# du coup on peut utiliser des metriques classiques pour le score (ici r2),\n",
    "# mais ca n'a aucun sens metier interpretable\n",
    "\n",
    "# ici convertir les tags en bag of words ou les one hot encoder revient exactement au meme, donc\n",
    "# autant utiliser le bow, on a deja le transformer.\n",
    "\n",
    "# ca prend trop de ressources ! Il est tps d'utiliser les nested runs de mlflow\n",
    "\n",
    "def pipe_knn(train_df=train, feature='title_nltk', target='all_tags', test_df=test, metric='cosine', graph=True):\n",
    "    # Load your training data and labels\n",
    "    X_train = train_df[feature].values\n",
    "    y_train = train_df[target].values\n",
    "\n",
    "    X_bow_matrix = token_list_into_bow(X_train)\n",
    "    y_bow_matrix = token_list_into_bow(y_train)\n",
    "\n",
    "    # Create a KNN Regressor\n",
    "    knn_regressor = KNeighborsRegressor(metric=metric)\n",
    "\n",
    "    # Create a pipeline with preprocessing and a knn regressor, to simplify gridsearch\n",
    "    pipe = Pipeline(steps=[\n",
    "        (\"knn_regressor\", knn_regressor)\n",
    "    ])\n",
    "\n",
    "    # Define hyperparameters and their possible values for grid search\n",
    "    param_grid = {\n",
    "        'knn_regressor__n_neighbors': [1],\n",
    "        'knn_regressor__weights': ['uniform'] # , 'distance'\n",
    "    }\n",
    "\n",
    "    # Create the GridSearchCV object with multiple scoring metrics\n",
    "    # scoring = {'neg_mean_squared_error': 'neg_mean_squared_error', 'r2': 'r2'}\n",
    "    grid_search = GridSearchCV(pipe, param_grid=param_grid,\n",
    "                            scoring='r2', cv=5, verbose=1) # add, refit='precision' for multiple scoring\n",
    "\n",
    "    # Fit the GridSearchCV object to your training data to perform hyperparameter tuning\n",
    "    grid_search.fit(X_bow_matrix, y_bow_matrix)\n",
    "\n",
    "    # Access the best hyperparameters\n",
    "    best_params = grid_search.best_params_\n",
    "    print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "    # Create the KNN regressor with the best hyperparameters\n",
    "    best_knn_regressor = KNeighborsRegressor(# metric=metric,\n",
    "                                             n_neighbors=best_params['knn_regressor__n_neighbors'],\n",
    "                                             weights=best_params['knn_regressor__weights'])\n",
    "\n",
    "    # Create a pipeline with the preprocessor and the tuned knn regressor\n",
    "    pipeline_with_tuned_knn = Pipeline(steps=[\n",
    "        (\"knn_regressor\", best_knn_regressor)  # Use the tuned neighbor and weight values here\n",
    "    ])\n",
    "\n",
    "    # Perform cross-validation (on training set) and display the scores for each split\n",
    "    # scoring = ['r2', 'neg_mean_squared_error']\n",
    "    cv_scores = cross_validate(pipeline_with_tuned_knn, X_bow_matrix, y_bow_matrix, cv=5, scoring='r2')\n",
    "    # print(\"Cross-Validation Scores (training):\", '\\n', cv_scores)\n",
    "    print(\"Cross-Validation Scores:\")\n",
    "    pprint(cv_scores)\n",
    "    for i, score in enumerate(cv_scores['test_score']):\n",
    "        print(f\"Split {i+1} : precision = {score}\")\n",
    "\n",
    "\n",
    "# pipe_knn()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mlflow runs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment knn_optimisation already exists.\n"
     ]
    }
   ],
   "source": [
    "experiment_id = create_mlflow_experiment(\n",
    "    experiment_name=\"knn_optimisation\",\n",
    "    artifact_location=\"./artifacts\",\n",
    "    tags={\"modele\": \"knn\", \"feature\": \"title\", 'nlp': 'nltk'},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: knn_optimisation\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "experiment = get_mlflow_experiment(experiment_id=experiment_id)\n",
    "print(\"Name: {}\".format(experiment.name))\n",
    "\n",
    "with mlflow.start_run(run_name=\"testing\", experiment_id=experiment_id) as run:\n",
    "\n",
    "    # log model using autolog\n",
    "    # mlflow.autolog()\n",
    "    mlflow.sklearn.autolog()\n",
    "    pipe_knn()\n",
    "\n",
    "    # print run info\n",
    "    print(\"run_id: {}\".format(run.info.run_id))\n",
    "    print(\"experiment_id: {}\".format(run.info.experiment_id))\n",
    "    print(\"Artifact Location: {}\".format(experiment.artifact_location))\n",
    "    print(\"status: {}\".format(run.info.status))\n",
    "    print(\"start_time: {}\".format(run.info.start_time))\n",
    "    print(\"end_time: {}\".format(run.info.end_time))\n",
    "    print(\"lifecycle_stage: {}\".format(run.info.lifecycle_stage))\n",
    "\n",
    "\n",
    "# J'esperais qu'mlflow allait nous permettre de contourner le probleme de\n",
    "# l'entrainement du modele, qui demande bcp d'espace memoire.\n",
    "# probleme : mm sans l'ui, le tracking/logging mlflow consomment enormement !\n",
    "# la solution a l'air pire que le probleme...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annexes, tests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "def predict_tags_using_rf(train_df=train[::100], feature='title_nltk', target='all_tags', test_df=test, n_estimators=50):\n",
    "    documents = train_df[feature].tolist()\n",
    "    gensim_dictionary = Dictionary(documents)\n",
    "    corpus = [gensim_dictionary.doc2bow(doc) for doc in documents]\n",
    "\n",
    "    # Convert Gensim corpus to dense matrix\n",
    "    dense_matrix = corpus2dense(corpus, num_terms=len(gensim_dictionary)).T\n",
    "\n",
    "    # Convert multi-label tags into binary format\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    y_encoded = mlb.fit_transform(train_df[target])\n",
    "\n",
    "    # Fit Random Forest model\n",
    "    rf_model = RandomForestRegressor(n_estimators=n_estimators, random_state=42)\n",
    "    rf_model.fit(dense_matrix, y_encoded)\n",
    "\n",
    "    # Predictions\n",
    "    predictions = []\n",
    "    min_range = 3000\n",
    "    max_range = 3005\n",
    "    for i in range(min_range, max_range):\n",
    "        query_document = test_df[feature][i]\n",
    "        print(f'doc {i} : {query_document}')\n",
    "        print(f'real tags : {test[target][i]}')\n",
    "        query_bow = gensim_dictionary.doc2bow(query_document)\n",
    "        query_vector = corpus2dense([query_bow], num_terms=len(gensim_dictionary)).T\n",
    "\n",
    "        # Predict tags using Random Forest\n",
    "        prediction_encoded = rf_model.predict(query_vector.reshape(1, -1))\n",
    "\n",
    "        # Convert back to original tag format\n",
    "        predicted_tags = mlb.inverse_transform(prediction_encoded.reshape(1, -1))\n",
    "\n",
    "        predictions.append(predicted_tags)\n",
    "        print(f'predicted : {predictions[-1]}', '\\n')\n",
    "\n",
    "    return predictions\n",
    "\n",
    "# Call the function with your DataFrame and the desired text feature and target tags\n",
    "predictions_rf = predict_tags_using_rf()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep learning Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv_p5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
