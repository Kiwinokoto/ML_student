{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## librairies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from common_imports import * ### ###\n",
    "\n",
    "import os, sys, random\n",
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Tuple\n",
    "from pandarallel import pandarallel\n",
    "from pprint import pprint\n",
    "import json\n",
    "import requests\n",
    "from collections import Counter\n",
    "\n",
    "# Visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from wordcloud import WordCloud\n",
    "from PIL import Image\n",
    "\n",
    "# NLP\n",
    "from bs4 import BeautifulSoup\n",
    "import re, string\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "#\n",
    "from gensim import corpora\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.matutils import corpus2dense\n",
    "from gensim.matutils import Sparse2Corpus\n",
    "from gensim.models import LdaModel, CoherenceModel\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "from gensim import similarities\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "\n",
    "#\n",
    "from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer, TransformedTargetRegressor\n",
    "from sklearn.metrics import make_scorer, PredictionErrorDisplay, r2_score\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "print('\\nPython version ' + sys.version)\n",
    "print('pyLDAvis version ' + pyLDAvis.__version__)\n",
    "\n",
    "# Modify if necessary\n",
    "num_cores = os.cpu_count()\n",
    "print(f\"\\nNumber of CPU cores: {num_cores}\")\n",
    "pandarallel.initialize(progress_bar=False, nb_workers=6)\n",
    "\n",
    "#\n",
    "import mlflow\n",
    "from mlflow import MlflowClient\n",
    "import mlflow.pyfunc\n",
    "from mlflow.models.signature import infer_signature, ModelSignature #, Schema, ParamSchema\n",
    "from mlflow.types import Schema, ParamSchema, ParamSpec, ColSpec\n",
    "\n",
    "# os.environ['MLFLOW_TRACKING_URI'] = './'\n",
    "\n",
    "# ! REQUIRES CONSOLE COMMAND : mlflow ui\n",
    "# depuis dossier notebooks\n",
    "# at least once, to creat mlruns folder\n",
    "\n",
    "# Utilisable seulement en local...\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "client = MlflowClient(tracking_uri=\"http://127.0.0.1:5000\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fonctions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mlflow_experiment(\n",
    "    experiment_name: str, artifact_location: str, tags: dict[str, str]\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Create a new mlflow experiment with the given name and artifact location.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    experiment_name: str\n",
    "        The name of the experiment to create.\n",
    "    artifact_location: str\n",
    "        The artifact location of the experiment to create.\n",
    "    tags: dict[str,Any]\n",
    "        The tags of the experiment to create.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    experiment_id: str\n",
    "        The id of the created experiment.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        experiment_id = mlflow.create_experiment(\n",
    "            name=experiment_name, artifact_location=artifact_location, tags=tags\n",
    "        )\n",
    "    except:\n",
    "        print(f\"Experiment {experiment_name} already exists.\")\n",
    "        experiment_id = mlflow.get_experiment_by_name(experiment_name).experiment_id\n",
    "\n",
    "    mlflow.set_experiment(experiment_name=experiment_name)\n",
    "\n",
    "    return experiment_id\n",
    "\n",
    "\n",
    "def get_mlflow_experiment(\n",
    "    experiment_id: str = None, experiment_name: str = None\n",
    ") -> mlflow.entities.Experiment:\n",
    "    \"\"\"\n",
    "    Retrieve the mlflow experiment with the given id or name.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    experiment_id: str\n",
    "        The id of the experiment to retrieve.\n",
    "    experiment_name: str\n",
    "        The name of the experiment to retrieve.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    experiment: mlflow.entities.Experiment\n",
    "        The mlflow experiment with the given id or name.\n",
    "    \"\"\"\n",
    "    if experiment_id is not None:\n",
    "        experiment = mlflow.get_experiment(experiment_id)\n",
    "    elif experiment_name is not None:\n",
    "        experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "    else:\n",
    "        raise ValueError(\"Either experiment_id or experiment_name must be provided.\")\n",
    "\n",
    "    return experiment\n",
    "\n",
    "\n",
    "def turn_str_back_into_list(df):\n",
    "    \"\"\"Correct the type change due to .csv export\"\"\"\n",
    "\n",
    "    df['title_nltk'] = df['title_nltk'].apply(ast.literal_eval)\n",
    "    df['body_nltk'] = df['body_nltk'].apply(ast.literal_eval)\n",
    "    df['title_spacy'] = df['title_spacy'].apply(ast.literal_eval)\n",
    "    df['body_spacy'] = df['body_spacy'].apply(ast.literal_eval)\n",
    "    df['all_tags'] = df['all_tags'].apply(ast.literal_eval)\n",
    "\n",
    "\n",
    "def token_list_into_bow(X):\n",
    "    documents = X.tolist()\n",
    "    # print(documents)\n",
    "    gensim_dictionary = Dictionary(documents)\n",
    "    corpus = [gensim_dictionary.doc2bow(doc) for doc in documents]\n",
    "\n",
    "    # Convert Gensim corpus to dense matrix\n",
    "    bow_matrix = corpus2dense(corpus, num_terms=len(gensim_dictionary)).T\n",
    "\n",
    "    return gensim_dictionary, bow_matrix\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "    #Cleaning\n",
    "    text = BeautifulSoup(text, 'html.parser').get_text()\n",
    "    text = text.lower().strip()\n",
    "\n",
    "    # Tokenization\n",
    "    try:\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "        tokenizer = nltk.RegexpTokenizer(r'\\w+')\n",
    "        tokens = tokenizer.tokenize(\" \".join(tokens))  # Apply RegexpTokenizer to the entire list\n",
    "\n",
    "        # Remove punctuation (make sure, RegexpTokenizer should have done it already)\n",
    "        tokens = [token for token in tokens if token not in string.punctuation]\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in tokenization: {e}\")\n",
    "        return []\n",
    "\n",
    "    # Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    # Get part of speech for each token\n",
    "    pos_tags = nltk.pos_tag(tokens)\n",
    "    lemmatized_tokens = []\n",
    "\n",
    "    for token, pos_tag in pos_tags:\n",
    "        # ! Uncommenting next line may crash the cell\n",
    "        # print(f\"Token: {token}, POS Tag: {pos_tag}\")\n",
    "        if pos_tag.startswith('V'):\n",
    "            # On garde\n",
    "            lemmatized_tokens.append(lemmatizer.lemmatize(token, pos='v'))\n",
    "            # Returns the input word unchanged if it cannot be found in WordNet.\n",
    "        elif pos_tag.startswith('N'):\n",
    "            # On garde\n",
    "            try:\n",
    "                lemmatized_tokens.append(lemmatizer.lemmatize(token, pos='n'))\n",
    "            except Exception as e:\n",
    "                print(f\"Error lemmatizing verb {token}: {e}\")\n",
    "        # Sinon on supprime\n",
    "\n",
    "    # Read forbidden words (stopwords, too frequent, too rare) from the file\n",
    "    with open('./../0_data/cleaned_data/forbidden_words.txt', 'r') as file:\n",
    "        forbidden = [line.strip() for line in file]\n",
    "\n",
    "    filtered_list = [token for token in lemmatized_tokens if token not in forbidden]\n",
    "\n",
    "    # keep uniques\n",
    "    seen_tokens = set()\n",
    "    unique_tokens = []\n",
    "\n",
    "    for token in filtered_list:\n",
    "        if token not in seen_tokens:\n",
    "            seen_tokens.add(token)\n",
    "            if len(token) > 2:\n",
    "                unique_tokens.append(token)\n",
    "\n",
    "    return unique_tokens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again, this needs mlfow ui console command first -> unusable on remote server\n",
    "# all_experiments = client.search_experiments()\n",
    "# pprint(all_experiments)\n",
    "\n",
    "train = pd.read_csv('./../0_data/cleaned_data/train_bow_uniques.csv', sep=',')\n",
    "test = pd.read_csv('./../0_data/cleaned_data/test_bow_uniques.csv', sep=',')\n",
    "\n",
    "turn_str_back_into_list(train)\n",
    "turn_str_back_into_list(test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add scorers : precision, r2, jaccard\n",
    "\n",
    "def precision_topics(real_tags:list, predicted_tags:list): # pour comparer 2 listes\n",
    "    # precision = TP / (TP + FP)\n",
    "    tp = 0\n",
    "    for predicted_tag in predicted_tags:\n",
    "        if predicted_tag in real_tags:\n",
    "            tp += 1\n",
    "\n",
    "    fp = len(predicted_tags) - tp\n",
    "    precision = tp/(tp + fp)\n",
    "    # <=> precision = tp/len(predicted_tags)\n",
    "\n",
    "    return precision\n",
    "\n",
    "def precision_score(y_true, y_pred): # pour comparer 2 df ou 2 matrices de mm shape[0]\n",
    "    precision = 0\n",
    "    for i in range(0, len(y_pred)):\n",
    "        precision += precision_topics(y_true[i], y_pred[i])\n",
    "    precision_moyenne = precision / len(y_pred)\n",
    "\n",
    "    return precision_moyenne\n",
    "\n",
    "# pour la gridsearchcv\n",
    "# custom_precision_scorer = make_scorer(precision_score, greater_is_better=True)\n",
    "\n",
    "\n",
    "def jaccard_similarity(topic1, topic2):\n",
    "    set1 = set(topic1)\n",
    "    set2 = set(topic2)\n",
    "    return len(set1.intersection(set2)) / len(set1.union(set2))\n",
    "\n",
    "def jaccard_score(y_true, y_pred): # pour comparer 2 df ou 2 matrices de mm shape[0]\n",
    "    jacc = 0\n",
    "    for i in range(0, len(y_pred)):\n",
    "        jacc += jaccard_similarity(y_true[i], y_pred[i])\n",
    "    jacc_moyen = jacc / len(y_pred)\n",
    "\n",
    "    return jacc_moyen\n",
    "\n",
    "# pour la gridsearchcv\n",
    "# custom_jacc_scorer = make_scorer(jaccard_score, greater_is_better=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## custom model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddN(mlflow.pyfunc.PythonModel):\n",
    "    \"\"\"\n",
    "    A custom model that adds a specified value `n` to all columns of the input DataFrame.\n",
    "\n",
    "    Attributes:\n",
    "    -----------\n",
    "    n : int\n",
    "        The value to add to input columns.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n):\n",
    "        \"\"\"\n",
    "        Constructor method. Initializes the model with the specified value `n`.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        n : int\n",
    "            The value to add to input columns.\n",
    "        \"\"\"\n",
    "        self.n = n\n",
    "\n",
    "    def predict(self, context, model_input, params=None):\n",
    "        \"\"\"\n",
    "        Prediction method for the custom model.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        context : Any\n",
    "            Ignored in this example. It's a placeholder for additional data or utility methods.\n",
    "\n",
    "        model_input : pd.DataFrame\n",
    "            The input DataFrame to which `n` should be added.\n",
    "\n",
    "        params : dict, optional\n",
    "            Additional prediction parameters. Ignored in this example.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        pd.DataFrame\n",
    "            The input DataFrame with `n` added to all columns.\n",
    "        \"\"\"\n",
    "        return model_input.apply(lambda column: column + self.n)\n",
    "\n",
    "\n",
    "# Instantiate the model with a specific value of n\n",
    "add_n_model = AddN(n=5)\n",
    "\n",
    "# Create a sample input DataFrame\n",
    "input_data = pd.DataFrame({\n",
    "    'column1': [1, 2, 3],\n",
    "    'column2': [4, 5, 6]\n",
    "})\n",
    "\n",
    "# Make predictions using the predict method\n",
    "predictions = add_n_model.predict(context=None, model_input=input_data, params=None)\n",
    "\n",
    "# Display the predictions\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### knn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpecialKnn(mlflow.pyfunc.PythonModel):\n",
    "    \"\"\"A special model \"\"\"\n",
    "\n",
    "    def __init__(self, k, n=5):\n",
    "        \"\"\"\n",
    "        Constructor method. Initializes the model with the specified value `n`.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        k : int\n",
    "        \"\"\"\n",
    "        self.k = k # nb voisins, shortcut pour l'attribut .n_neighbors\n",
    "        self.n = n # nb tags predits\n",
    "        self.knn = KNeighborsRegressor(n_neighbors=k)\n",
    "        self.dict_X = Dictionary()\n",
    "        self.dict_y = Dictionary()\n",
    "\n",
    "    def load_context(self, context):\n",
    "        # when instance is created\n",
    "        # on l'utilisera + tard, pour recup rapidement de \"gros\" modeles deja entraines\n",
    "        pass\n",
    "\n",
    "\n",
    "    def fit(self, train_df, feature, target):\n",
    "        X_train = train_df[feature].values\n",
    "        y_train = train_df[target].values\n",
    "\n",
    "        self.dict_X, X_bow_matrix = token_list_into_bow(X_train)\n",
    "        self.dict_y, y_bow_matrix = token_list_into_bow(y_train)\n",
    "\n",
    "        # Create a KNN Regressor\n",
    "        self.knn.fit(X_bow_matrix, y_bow_matrix)\n",
    "\n",
    "\n",
    "    def predict_tokens(self, input_text, train_df=train, target='all_tags'):\n",
    "        \"\"\"Prediction method for the custom model.\"\"\"\n",
    "        # Example query\n",
    "        query_tokens = preprocess_text(input_text)\n",
    "        print(query_tokens)\n",
    "        query_bow = self.dict_X.doc2bow(query_tokens)\n",
    "        query_vector = corpus2dense([query_bow], num_terms=len(self.dict)).T\n",
    "\n",
    "        # Find nearest neighbors\n",
    "        _, indices = self.knn.kneighbors(query_vector)\n",
    "\n",
    "        # Aggregate tags from neighbors\n",
    "        neighbor_tags = [tag for i in indices.flatten() for tag in train_df.iloc[i][target]]\n",
    "\n",
    "        # Predict tags based on most common tags among neighbors\n",
    "        predicted_tags = [tag for tag, _ in Counter(neighbor_tags).most_common(n=5)]\n",
    "        # 5 tags/question en moyenne mais on peut suggérer +\n",
    "        # ici a ameliorer\n",
    "\n",
    "        return predicted_tags\n",
    "\n",
    "    # scores\n",
    "\n",
    "\n",
    "\n",
    "# Instantiate the model with a specific value of n\n",
    "my_knn = SpecialKnn(k=50)\n",
    "\n",
    "my_knn.fit(train_df=train, feature='title_nltk', target='all_tags')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_knn.predict_tokens('javascript')\n",
    "# my_knn.predict_tokens('python')\n",
    "\n",
    "# print(str(test['title_nltk'][0]))\n",
    "# my_knn.predict_tokens(str(test['title_nltk'][0]))\n",
    "\n",
    "my_knn.predict_tokens('find class com google firebase provider')\n",
    "\n",
    "# perfect\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test sans le preprocessor\n",
    "# obligé de transformer la target mm si on ne s'sn sert pas vraiment, car grid_search.fit()\n",
    "# n'accepte que des valeurs numériques.\n",
    "# du coup on peut utiliser des metriques classiques pour le score (ici r2),\n",
    "# mais ca n'a aucun sens metier interpretable\n",
    "\n",
    "# ici convertir les tags en bag of words ou les one hot encoder revient exactement au meme, donc\n",
    "# autant utiliser le bow, on a deja le transformer.\n",
    "\n",
    "# ca prend trop de ressources ! Il est tps d'utiliser les nested runs de mlflow\n",
    "\n",
    "def pipe_knn(train_df=train, feature='title_nltk', target='all_tags', test_df=test, input=['']):\n",
    "    # Load your training data and labels\n",
    "    X_train = train_df[feature].values\n",
    "    y_train = train_df[target].values\n",
    "\n",
    "    X_bow_matrix = token_list_into_bow(X_train)\n",
    "    y_bow_matrix = token_list_into_bow(y_train)\n",
    "\n",
    "    # Create a KNN Regressor\n",
    "    knn_regressor = KNeighborsRegressor()\n",
    "\n",
    "    # Create a pipeline with preprocessing and a knn regressor, to simplify gridsearch\n",
    "    pipe = Pipeline(steps=[\n",
    "        (\"knn_regressor\", knn_regressor)\n",
    "    ])\n",
    "\n",
    "    # Define hyperparameters and their possible values for grid search\n",
    "    param_grid = {\n",
    "        'knn_regressor__n_neighbors': [1],\n",
    "        'knn_regressor__weights': ['uniform'] # , 'distance'\n",
    "    }\n",
    "\n",
    "    # Create the GridSearchCV object with multiple scoring metrics\n",
    "    # scoring = {'neg_mean_squared_error': 'neg_mean_squared_error', 'r2': 'r2'}\n",
    "    grid_search = GridSearchCV(pipe, param_grid=param_grid,\n",
    "                            scoring='r2', cv=5, verbose=1) # add, refit='precision' for multiple scoring\n",
    "\n",
    "    # Fit the GridSearchCV object to your training data to perform hyperparameter tuning\n",
    "    grid_search.fit(X_bow_matrix, y_bow_matrix)\n",
    "\n",
    "    # Access the best hyperparameters\n",
    "    best_params = grid_search.best_params_\n",
    "    print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "    # Create the KNN regressor with the best hyperparameters\n",
    "    best_knn_regressor = KNeighborsRegressor(# metric=metric,\n",
    "                                             n_neighbors=best_params['knn_regressor__n_neighbors'],\n",
    "                                             weights=best_params['knn_regressor__weights'])\n",
    "\n",
    "    # Create a pipeline with the preprocessor and the tuned knn regressor\n",
    "    pipeline_with_tuned_knn = Pipeline(steps=[\n",
    "        (\"knn_regressor\", best_knn_regressor)  # Use the tuned neighbor and weight values here\n",
    "    ])\n",
    "\n",
    "    # Perform cross-validation (on training set) and display the scores for each split\n",
    "    # scoring = ['r2', 'neg_mean_squared_error']\n",
    "    cv_scores = cross_validate(pipeline_with_tuned_knn, X_bow_matrix, y_bow_matrix, cv=5, scoring='r2')\n",
    "    # print(\"Cross-Validation Scores (training):\", '\\n', cv_scores)\n",
    "    print(\"Cross-Validation Scores:\")\n",
    "    pprint(cv_scores)\n",
    "    for i, score in enumerate(cv_scores['test_score']):\n",
    "        print(f\"Split {i+1} : precision = {score}\")\n",
    "\n",
    "    return best_knn_regressor.predict(input)\n",
    "\n",
    "\n",
    "# pipe_knn()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mlflow runs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i was wondering : isn't optimising the number of neighbors hyperparameter of a knn via gridsearhcv a bad idea ? because the gridsearch will use folds to train the models. but folds are smaller subsets, and the optimal number of neighbor for a knn depends on the size of the training dataset.\n",
    "ChatGPT\n",
    "You raise a valid point. When optimizing hyperparameters for a k-Nearest Neighbors (KNN) model using cross-validation, there are considerations regarding the choice of the number of neighbors (n_neighbors) and the impact of the size of the training dataset on this hyperparameter.\n",
    "\n",
    "In KNN, the optimal number of neighbors can indeed depend on the characteristics of the training data. If you have a small training dataset, a small number of neighbors might be sufficient, while a larger dataset might benefit from a larger number of neighbors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tester hyperopt ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_id = create_mlflow_experiment(\n",
    "    experiment_name=\"knn_optimisation_neighbors\",\n",
    "    artifact_location=\"./artifacts\",\n",
    "    tags={\"modele\": \"knn\", \"feature\": \"title\", 'nlp': 'nltk'},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = get_mlflow_experiment(experiment_id=experiment_id)\n",
    "print(\"Name: {}\".format(experiment.name))\n",
    "\n",
    "with mlflow.start_run(run_name=\"testing\", experiment_id=experiment_id) as run:\n",
    "\n",
    "    # log model using autolog crashes the notebook\n",
    "    # mlflow.autolog()\n",
    "    # mlflow.sklearn.autolog()\n",
    "\n",
    "    pipe_knn(train_df=train[:100])\n",
    "\n",
    "    # log model\n",
    "    mlflow.sklearn.log_model(sk_model=SpecialKnn(), artifact_path=\"knn\")\n",
    "    # mlflow.pyfunc.log_model(artifact_path=\"knn\", python_model=KNeighborsRegressor())\n",
    "\n",
    "    # print run info\n",
    "    print(\"run_id: {}\".format(run.info.run_id))\n",
    "    print(\"experiment_id: {}\".format(run.info.experiment_id))\n",
    "    print(\"Artifact Location: {}\".format(experiment.artifact_location))\n",
    "    print(\"status: {}\".format(run.info.status))\n",
    "    print(\"start_time: {}\".format(run.info.start_time))\n",
    "    print(\"end_time: {}\".format(run.info.end_time))\n",
    "    # print(\"lifecycle_stage: {}\".format(run.info.lifecycle_stage)) # deprecated, use alias or tags\n",
    "\n",
    "\n",
    "# J'esperais qu'mlflow allait nous permettre de contourner le probleme de\n",
    "# l'entrainement du modele, qui demande bcp d'espace memoire.\n",
    "# probleme : mm sans l'ui, le tracking/logging mlflow consomment enormement !\n",
    "# la solution a l'air pire que le probleme...\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv_p5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
