{"cells":[{"attachments":{},"cell_type":"markdown","id":"c10447d1","metadata":{"id":"c10447d1"},"source":["# **Catégorisez automatiquement des questions**\n","\n","## partie 1/8 : analyse exploratoire\n","\n","### <br> Notebook d’exploration et de pré-traitement des questions, comprenant une analyse univariée et multivariée, un nettoyage des questions, un feature engineering de type bag of words avec réduction de dimension (du vocabulaire et des tags) \n","\n","<br>\n"]},{"cell_type":"markdown","metadata":{},"source":["## 1 Objectifs, imports\n"]},{"cell_type":"markdown","metadata":{},"source":["### 1.1 Contexte\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# Nous avons téléchargé 50 000 questions posées sur stack overflow,\n","# ainsi que les tags associés.\n","\n","# Objectifs de notebook :\n","\n","# Comprendre nos données (forme, structure)\n","# premier nettoyage -> reduction dim\n","# Avoir une première représentation de nos données\n","# Rechercher des patterns\n","# se faire une idée de la difficulté de la tâche (prédiction de tags)\n","# (encore et surtout) : transformations en vue de reduction dim\n","\n","# => traitement de strings avec nltk, regex, etc..\n","# tester spacy\n","\n","# Dans le cadre de ce projet :\n","# Nous avons en input un fichier csv contenant 50 000 titres, questions (body), tags, etc...\n","# Nous avons besoin en output de représentations spécifiques, pour nos différents modèles.\n","\n","# Pour les modèles non-supervisé, il nous faut :\n","# - un bag of words pour la LDA (/algos similaires)\n","# - un TS-IDF pour la NMF\n","# Dans les deux cas, cela implique un cleaning \"aggressif\", visant à conserver uniquement\n","# les mots qui ont du sens pour ce projet (= qui aident la prédiction de tag par les modèles).\n","# encore et tjs, la reduction dim !\n","\n","# / supervisés ?\n"]},{"attachments":{},"cell_type":"markdown","id":"8cf10133","metadata":{"id":"8cf10133"},"source":["### 1.2 Importation des librairies, réglages\n"]},{"cell_type":"code","execution_count":2,"id":"6ffe8b0d","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9566,"status":"ok","timestamp":1688504146442,"user":{"displayName":"Kevin Oudelet","userId":"05301463766297982835"},"user_tz":-120},"id":"6ffe8b0d","outputId":"4abc7d5f-4fe6-46db-fa59-05891e583e93"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package punkt to /home/ubuntu/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to /home/ubuntu/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package wordnet to /home/ubuntu/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /home/ubuntu/nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n","[nltk_data]       date!\n","2023-12-06 18:23:55.795089: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"]},{"name":"stdout","output_type":"stream","text":["\n","Python version 3.11.4 (main, Jul  5 2023, 14:15:25) [GCC 11.2.0]\n","pandas version 2.1.1\n","sns version 0.12.2\n","\n","Number of CPU cores: 8\n","INFO: Pandarallel will run on 6 workers.\n","INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"]}],"source":["import os, sys, random\n","from zipfile import ZipFile\n","import numpy as np\n","import pandas as pd\n","\n","# Visualisation\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import plotly.express as px\n","import plotly.graph_objects as go\n","from wordcloud import WordCloud\n","from PIL import Image\n","\n","# NLP\n","from bs4 import BeautifulSoup\n","import re, string\n","import nltk\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","from nltk.stem import WordNetLemmatizer\n","from nltk.corpus import wordnet\n","nltk.download('wordnet')\n","nltk.download('averaged_perceptron_tagger')\n","from collections import Counter\n","# if necessary\n","# !python -m spacy download en_core_web_sm\n","# !python -m spacy download en_core_web_md\n","import spacy\n","\n","from pandarallel import pandarallel\n","\n","print('\\nPython version ' + sys.version)\n","print('pandas version ' + pd.__version__)\n","print('sns version ' + sns.__version__)\n","\n","plt.style.use('ggplot')\n","pd.set_option('display.max_columns', 200)\n","sns.set(font_scale=1)\n","\n","# Make sure we downloaded the models successfully\n","nlp = spacy.load(\"en_core_web_sm\")\n","nlp = spacy.load(\"en_core_web_md\")\n","\n","num_cores = os.cpu_count()\n","print(f\"\\nNumber of CPU cores: {num_cores}\")\n","\n","pandarallel.initialize(progress_bar=False, nb_workers=6)\n"]},{"cell_type":"markdown","id":"6dc1e6dd","metadata":{},"source":["### 1.3 Fonctions\n"]},{"cell_type":"code","execution_count":3,"id":"76f32233","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[(0.745, 0.627, 0.949, 1.0), (0.929, 0.808, 0.855, 1.0)]\n"]}],"source":["# Principalement des fonctions pour l'affichage des graphiques pdt l'EDA\n","\n","def quick_look(df, miss=True):\n","    \"\"\"\n","    Display a quick overview of a DataFrame, including shape, head, tail, unique values, and duplicates.\n","\n","    Args:\n","        df (pandas.DataFrame): The input DataFrame to inspect.\n","        check_missing (bool, optional): Whether to check and display missing values (default is True).\n","\n","    The function provides a summary of the DataFrame, including its shape, the first and last rows, the count of unique values per column, and the number of duplicates.\n","    If `check_missing` is set to True, it also displays missing value information.\n","    \"\"\"\n","    print(f'shape : {df.shape}')\n","\n","    display(df.head())\n","    display(df.tail())\n","\n","    print('uniques :')\n","    display(df.nunique())\n","\n","    print('Doublons ? ', df.duplicated(keep='first').sum(), '\\n')\n","\n","    if miss:\n","        display(get_missing_values(df))\n","\n","\n","def lerp(a, b, t):\n","    \"\"\"\n","    Linear interpolation between two values 'a' and 'b' at a parameter 't'.\n","    A very useful little function, used here to position annotations in plots.\n","    Got it coding with Radu :)\n","\n","    Given two values 'a' and 'b', and a parameter 't',\n","    this function calculates the linear interpolation between 'a' and 'b' at 't'.\n","\n","    Parameters:\n","    a (float or int): The start value.\n","    b (float or int): The end value.\n","    t (float): The interpolation parameter (typically in the range [0, 1], but can be outside).\n","\n","    Returns:\n","    float or int: The interpolated value at parameter 't'.\n","    \"\"\"\n","    return a + (b - a) * t\n","\n","\n","def generate_random_pastel_colors(n):\n","    \"\"\"\n","    Generates a list of n random pastel colors, represented as RGBA tuples.\n","\n","    Parameters:\n","    n (int): The number of pastel colors to generate.\n","\n","    Returns:\n","    list: A list of RGBA tuples representing random pastel colors.\n","\n","    Example:\n","    >>> generate_random_pastel_colors(2)\n","    [(0.749, 0.827, 0.886, 1.0), (0.886, 0.749, 0.827, 1.0)]\n","    \"\"\"\n","    colors = []\n","    for _ in range(n):\n","        # Generate random pastels\n","        red = round(random.randint(150, 250) / 255.0, 3)\n","        green = round(random.randint(150, 250) / 255.0, 3)\n","        blue = round(random.randint(150, 250) / 255.0, 3)\n","\n","        # Create an RGB color tuple and add it to the list\n","        color = (red,green,blue, 1.0)\n","        colors.append(color)\n","\n","    return colors\n","\n","print(generate_random_pastel_colors(2))\n","\n","\n","def get_missing_values(df):\n","    \"\"\"Generates a DataFrame containing the count and proportion of missing values for each feature.\n","\n","    Args:\n","        df (pandas.DataFrame): The input DataFrame to analyze.\n","\n","    Returns:\n","        pandas.DataFrame: A DataFrame with columns for the feature name, count of missing values,\n","        count of non-missing values, proportion of missing values, and data type for each feature.\n","    \"\"\"\n","    # Count the missing values for each column\n","    missing = df.isna().sum()\n","\n","    # Calculate the percentage of missing values\n","    percent_missing = df.isna().mean() * 100\n","\n","    # Create a DataFrame to store the results\n","    missings_df = pd.DataFrame({\n","        'column_name': df.columns,\n","        'missing': missing,\n","        'present': df.shape[0] - missing,  # Count of non-missing values\n","        'percent_missing': percent_missing.round(2),  # Rounded to 2 decimal places\n","        'type': df.dtypes\n","    })\n","\n","    # Sort the DataFrame by the count of missing values\n","    missings_df.sort_values('missing', inplace=True)\n","\n","    return missings_df\n","\n","# with pd.option_context('display.max_rows', 1000):\n","#   display(get_missing_values(df))\n","\n","\n","def hist_distrib(dataframe, feature, bins, decimal_places, density=True):\n","    \"\"\"\n","    Visualize the empirical distribution of a numerical feature using a histogram.\n","    Calcul des principaux indicateurs de tendance centrale, dispersion et forme.\n","\n","    Args:\n","        dataframe (pandas.DataFrame): The input DataFrame containing the feature.\n","        feature (str): The name of the numerical feature to visualize.\n","        bins (int): The number of bins for the histogram.\n","        decimal_places (int): The number of decimal places for rounding numeric values.\n","        density (bool, optional): Whether to display the histogram as a density plot (default is True).\n","\n","    Returns:\n","        float: The skewness of the feature's distribution.\n","\n","    The function generates a histogram of the feature, displays various statistics, and returns the skewness of the distribution.\n","    \"\"\"\n","    # Calculate central tendencies and dispersion\n","    mode_value = round(dataframe[feature].mode()[0], decimal_places)\n","    mode_non_zero = \"N/A\"\n","    if (dataframe[feature] != 0).any():\n","        mode_non_zero = round(dataframe.loc[dataframe[feature] != 0, feature].mode()[0], decimal_places)\n","    median_value = round(dataframe[feature].median(), decimal_places)\n","    mean_value = round(dataframe[feature].mean(), decimal_places)\n","\n","    # Calculate dispersion\n","    var_emp = round(dataframe[feature].var(ddof=0), decimal_places)\n","    coeff_var = round(dataframe[feature].std(ddof=0), decimal_places)\n","\n","    # Calculate shape indicators\n","    skewness_value = round(dataframe[feature].skew(), 2)\n","    kurtosis_value = round(dataframe[feature].kurtosis(), 2)\n","\n","    # Create the plot\n","    fig, ax = plt.subplots(figsize=(12, 5))\n","    dataframe[feature].hist(density=density, bins=bins, ax=ax)\n","\n","    # Adjust placement for annotations\n","    yt = plt.yticks()\n","    y_position = lerp(yt[0][0], yt[0][-1], 0.8)\n","    y_increment = y_position / 20\n","    xt = plt.xticks()\n","    x_position = lerp(xt[0][0], xt[0][-1], 0.7)\n","\n","    # Add annotations with horizontal and vertical alignment\n","    annotation_fs = 13\n","    color = 'g'\n","    ax.annotate(f'Mode: {mode_value}', xy=(x_position, y_position), fontsize=annotation_fs,\n","                xytext=(x_position, y_position), color=color, ha='left', va='bottom')\n","    ax.annotate(f'Mode +: {mode_non_zero}', xy=(x_position, y_position - y_increment), fontsize=annotation_fs,\n","                xytext=(x_position, y_position - y_increment), color=color, ha='left', va='bottom')\n","    ax.annotate(f'Median: {median_value}', xy=(x_position, y_position - 2 * y_increment), fontsize=annotation_fs,\n","                xytext=(x_position, y_position - 2 * y_increment), color=color, ha='left', va='bottom')\n","    ax.annotate(f'Mean: {mean_value}', xy=(x_position, y_position - 3 * y_increment), fontsize=annotation_fs,\n","                xytext=(x_position, y_position - 3 * y_increment), color=color, ha='left', va='bottom')\n","    ax.annotate(f'Var Emp: {var_emp}', xy=(x_position, y_position - 5 * y_increment), fontsize=annotation_fs,\n","                xytext=(x_position, y_position - 5 * y_increment), color=color, ha='left', va='bottom')\n","    ax.annotate(f'Coeff Var: {coeff_var}', xy=(x_position, y_position - 6 * y_increment), fontsize=annotation_fs,\n","                xytext=(x_position, y_position - 6 * y_increment), color=color, ha='left', va='bottom')\n","    ax.annotate(f'Skewness: {skewness_value}', xy=(x_position, y_position - 8 * y_increment), fontsize=annotation_fs,\n","                xytext=(x_position, y_position - 8 * y_increment), color=color, ha='left', va='bottom')\n","    ax.annotate(f'Kurtosis: {kurtosis_value}', xy=(x_position, y_position - 9 * y_increment), fontsize=annotation_fs,\n","                xytext=(x_position, y_position - 9 * y_increment), color=color, ha='left', va='bottom')\n","\n","    # Label the x-axis and y-axis\n","    ax.set_xlabel(feature, fontsize=12)\n","    ax.set_ylabel('Frequency', fontsize=12)\n","\n","    # Show the plot\n","    plt.title(f'Distribution of {feature}', pad=20, fontsize=18)\n","    plt.xticks(fontsize=12)\n","    plt.yticks(fontsize=12)\n","    plt.show()\n","\n","    return skewness_value\n","\n","\n","def boxplot_distrib(dataframe, feature):\n","    \"\"\"\n","    Affiche un boxplot, pour visualiser les tendances centrales et la dispersion d'une variable.\n","\n","    Args:\n","        dataframe (pandas.DataFrame): The input DataFrame containing the feature.\n","        feature (str): The name of the numerical feature to visualize.\n","\n","    The function generates a box plot of the feature to display central tendencies (median and mean) and dispersion.\n","    \"\"\"\n","    fig, ax = plt.subplots(figsize=(10, 4))\n","\n","    medianprops = {'color':\"blue\"}\n","    meanprops = {'marker':'o', 'markeredgecolor':'black',\n","            'markerfacecolor':'firebrick'}\n","\n","    dataframe.boxplot(feature, vert=False, showfliers=False, medianprops=medianprops, patch_artist=True, showmeans=True, meanprops=meanprops)\n","\n","    plt.xticks(fontsize=12)\n","    plt.yticks(fontsize=12)\n","    plt.show()\n","\n","\n","def courbe_lorenz(dataframe, feature):\n","    \"\"\"\n","    Affiche une courbe de Lorenz, pour visualiser la concentration d'une variable\n","    Calcule l'indice de Gini\n","    Visualize a Lorenz curve to assess the concentration of a variable and calculate the Gini coefficient.\n","\n","    Args:\n","        dataframe (pandas.DataFrame): The input DataFrame containing the feature.\n","        feature (str): The name of the numerical feature to visualize.\n","\n","    The function generates a Lorenz curve to assess the concentration of the feature and calculates the Gini coefficient.\n","    \"\"\"\n","    fig, ax = plt.subplots(figsize=(12, 5))\n","    values = dataframe.loc[dataframe[feature].notna(), feature].values\n","    # print(values)\n","    n = len(values)\n","    lorenz = np.cumsum(np.sort(values)) / values.sum()\n","    lorenz = np.append([0],lorenz) # La courbe de Lorenz commence à 0\n","\n","    xaxis = np.linspace(0-1/n,1+1/n,n+1)\n","    #Il y a un segment de taille n pour chaque individu, plus 1 segment supplémentaire d'ordonnée 0.\n","    # #Le premier segment commence à 0-1/n, et le dernier termine à 1+1/n.\n","    plt.plot(xaxis,lorenz,drawstyle='steps-post')\n","    plt.plot(np.arange(2),[x for x in np.arange(2)])\n","    # calcul de l'indice de Gini\n","    AUC = (lorenz.sum() -lorenz[-1]/2 -lorenz[0]/2)/n # Surface sous la courbe de Lorenz. Le premier segment (lorenz[0]) est à moitié en dessous de 0, on le coupe donc en 2, on fait de même pour le dernier segment lorenz[-1] qui est à moitié au dessus de 1.\n","    S = 0.5 - AUC # surface entre la première bissectrice et le courbe de Lorenz\n","    gini = 2*S\n","    plt.annotate('gini =  ' + str(round(gini, 2)), xy = (0.04, 0.88), fontsize = 13, xytext = (0.04, 0.88), color = 'g')\n","    plt.xticks(fontsize=12)\n","    plt.yticks(fontsize=12)\n","    plt.show()\n","\n","\n","def graphs_analyse_uni(dataframe, feature, bins=50, r=5, density=True):\n","    \"\"\"\n","    Affiche histogramme + boxplot + courbe de Lorenz\n","\n","    Args:\n","        dataframe (pandas.DataFrame): The input DataFrame containing the feature.\n","        feature (str): The name of the numerical feature to analyze.\n","        bins (int, optional): The number of bins for the histogram (default is 50).\n","        decimal_places (int, optional): The number of decimal places for rounding numeric values (default is 5).\n","        density (bool, optional): Whether to display the histogram as a density plot (default is True).\n","\n","    The function generates and displays an analysis of the given numerical feature, including an histogram, a box plot, and a Lorenz curve.\n","    \"\"\"\n","    hist_distrib(dataframe, feature, bins, r)\n","    boxplot_distrib(dataframe, feature)\n","    courbe_lorenz(dataframe, feature)\n","\n","\n","def shape_head(df, nb_rows=5):\n","    \"\"\"\n","    Affiche les dimensions et les premières lignes dùun dataframe\n","    Display the dimensions and the first rows of a DataFrame.\n","\n","    Args:\n","        df (pandas.DataFrame): The input DataFrame to display.\n","        nb_rows (int, optional): The number of rows to display (default is 5, max is 60).\n","\n","    The function prints the dimensions of the DataFrame and displays the first few rows.\n","    \"\"\"\n","    print(df.shape)\n","    display(df.head(nb_rows))\n","\n","\n","def doughnut(df, feature, title, width=10, height=10):\n","    \"\"\"\n","    Affiche la répartition d'une feature sous forme de diagramme circulaire\n","    Display the distribution of a feature as a doughnut chart.\n","    Les couleurs sont aléatoires.\n","\n","    Args:\n","        df (pandas.DataFrame): The input DataFrame containing the feature.\n","        feature (str): The name of the feature to visualize.\n","        title (str): The title for the doughnut chart.\n","        width (int, optional): The width of the chart (default is 10).\n","        height (int, optional): The height of the chart (default is 10).\n","\n","    The function creates a doughnut chart to visualize the distribution of the specified feature.\n","    If you don't like the colors, try running it again :)\n","    \"\"\"\n","    colors = generate_random_pastel_colors(20)\n","\n","    grouped_df = df.groupby(feature).size().to_frame(\"count_per_type\").reset_index()\n","    pie = grouped_df.set_index(feature).copy()\n","\n","    fig, ax = plt.subplots(figsize=(width, height))\n","\n","    patches, texts, autotexts = plt.pie(x=pie['count_per_type'], autopct='%1.1f%%',\n","        startangle=-30, labels=pie.index, textprops={'fontsize':11, 'color':'#000'},\n","        labeldistance=1.25, pctdistance=0.85, colors=colors)\n","\n","    plt.title(\n","    label=title,\n","    fontdict={\"fontsize\":17},\n","    pad=20\n","    )\n","\n","    for text in texts:\n","        # text.set_fontweight('bold')\n","        text.set_horizontalalignment('center')\n","\n","    # Customize percent labels\n","    for autotext in autotexts:\n","        autotext.set_horizontalalignment('center')\n","        autotext.set_fontstyle('italic')\n","        autotext.set_fontsize('10')\n","\n","    #draw circle\n","    centre_circle = plt.Circle((0,0),0.7,fc='white')\n","    fig = plt.gcf()\n","    fig.gca().add_artist(centre_circle)\n","\n","    plt.show()\n","\n","\n","def get_non_null_values(df):\n","    \"\"\"\n","    Génère un dataframe contenant le nombre et la proportion de non-null (non-zero) valeurs pour chaque feature\n","    Generate a DataFrame containing the count and proportion of non-null (non-zero) values for each feature.\n","\n","    Args:\n","        df (pandas.DataFrame): The input DataFrame to analyze.\n","\n","    The function calculates and returns a DataFrame with the count and percentage of non-null (non-zero) values for each feature.\n","    \"\"\"\n","    non_null_counts = df.ne(0).sum()\n","    percent_non_null = (non_null_counts / df.shape[0]) * 100\n","    non_null_values_df = pd.DataFrame({'column_name': df.columns,\n","                                       'non_null_count': non_null_counts,\n","                                       'percent_non_null': percent_non_null.round(2),\n","                                       'type': df.dtypes})\n","    non_null_values_df.sort_values('non_null_count', inplace=True)\n","    return non_null_values_df\n","\n","\n","def get_colors(n=7):\n","    \"\"\"\n","    Generate a list of random colors from multiple colormaps.\n","\n","    Args:\n","        n (int, optional): The number of colors to sample from each colormap (default is 7).\n","\n","    Returns:\n","        list: A list of random colors sampled from different colormaps.\n","    \"\"\"\n","    num_colors_per_colormap = n\n","    colormaps = [plt.cm.Pastel2, plt.cm.Set1, plt.cm.Paired]\n","    all_colors = []\n","\n","    for colormap in colormaps:\n","        colors = colormap(np.linspace(0, 1, num_colors_per_colormap))\n","        all_colors.extend(colors)\n","\n","    np.random.shuffle(all_colors)\n","\n","    return all_colors\n"]},{"cell_type":"markdown","metadata":{},"source":["## 2 EDA et preprocessing des questions\n"]},{"attachments":{},"cell_type":"markdown","id":"a334fc5e","metadata":{"id":"a334fc5e"},"source":["### 2.1 Importation des données brutes\n"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["shape : (50000, 9)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Title</th>\n","      <th>Body</th>\n","      <th>Tags</th>\n","      <th>Id</th>\n","      <th>Score</th>\n","      <th>ViewCount</th>\n","      <th>FavoriteCount</th>\n","      <th>AnswerCount</th>\n","      <th>CreationDate</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>ImportError: cannot import name 'url_decode' f...</td>\n","      <td>&lt;p&gt;I am building a webapp using Flask. I impor...</td>\n","      <td>&lt;python&gt;&lt;flask&gt;&lt;importerror&gt;&lt;flask-login&gt;&lt;werk...</td>\n","      <td>77215107</td>\n","      <td>13</td>\n","      <td>14443</td>\n","      <td>NaN</td>\n","      <td>5</td>\n","      <td>2023-10-02 11:07:45</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Compilation error after upgrading to JDK 21 - ...</td>\n","      <td>&lt;p&gt;After upgrading to JDK 21, I have the follo...</td>\n","      <td>&lt;spring-boot&gt;&lt;compiler-errors&gt;&lt;upgrade&gt;&lt;lombok...</td>\n","      <td>77171270</td>\n","      <td>55</td>\n","      <td>36788</td>\n","      <td>NaN</td>\n","      <td>3</td>\n","      <td>2023-09-25 09:05:11</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Differences between Langchain &amp; LlamaIndex</td>\n","      <td>&lt;p&gt;I'm currently working on developing a chatb...</td>\n","      <td>&lt;chatbot&gt;&lt;openai-api&gt;&lt;langchain&gt;&lt;large-languag...</td>\n","      <td>76990736</td>\n","      <td>28</td>\n","      <td>10433</td>\n","      <td>NaN</td>\n","      <td>2</td>\n","      <td>2023-08-28 07:22:32</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>session not created: This version of ChromeDri...</td>\n","      <td>&lt;p&gt;I am running a Docker image from a Docker c...</td>\n","      <td>&lt;python&gt;&lt;amazon-web-services&gt;&lt;docker&gt;&lt;google-c...</td>\n","      <td>76909437</td>\n","      <td>14</td>\n","      <td>14969</td>\n","      <td>NaN</td>\n","      <td>8</td>\n","      <td>2023-08-15 22:21:03</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Spring security method cannot decide pattern i...</td>\n","      <td>&lt;p&gt;When I try to run an application it fails t...</td>\n","      <td>&lt;java&gt;&lt;spring-boot&gt;&lt;eclipse&gt;&lt;spring-security&gt;&lt;...</td>\n","      <td>76809698</td>\n","      <td>27</td>\n","      <td>18943</td>\n","      <td>NaN</td>\n","      <td>8</td>\n","      <td>2023-08-01 08:16:21</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                               Title  \\\n","0  ImportError: cannot import name 'url_decode' f...   \n","1  Compilation error after upgrading to JDK 21 - ...   \n","2         Differences between Langchain & LlamaIndex   \n","3  session not created: This version of ChromeDri...   \n","4  Spring security method cannot decide pattern i...   \n","\n","                                                Body  \\\n","0  <p>I am building a webapp using Flask. I impor...   \n","1  <p>After upgrading to JDK 21, I have the follo...   \n","2  <p>I'm currently working on developing a chatb...   \n","3  <p>I am running a Docker image from a Docker c...   \n","4  <p>When I try to run an application it fails t...   \n","\n","                                                Tags        Id  Score  \\\n","0  <python><flask><importerror><flask-login><werk...  77215107     13   \n","1  <spring-boot><compiler-errors><upgrade><lombok...  77171270     55   \n","2  <chatbot><openai-api><langchain><large-languag...  76990736     28   \n","3  <python><amazon-web-services><docker><google-c...  76909437     14   \n","4  <java><spring-boot><eclipse><spring-security><...  76809698     27   \n","\n","   ViewCount  FavoriteCount  AnswerCount         CreationDate  \n","0      14443            NaN            5  2023-10-02 11:07:45  \n","1      36788            NaN            3  2023-09-25 09:05:11  \n","2      10433            NaN            2  2023-08-28 07:22:32  \n","3      14969            NaN            8  2023-08-15 22:21:03  \n","4      18943            NaN            8  2023-08-01 08:16:21  "]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Title</th>\n","      <th>Body</th>\n","      <th>Tags</th>\n","      <th>Id</th>\n","      <th>Score</th>\n","      <th>ViewCount</th>\n","      <th>FavoriteCount</th>\n","      <th>AnswerCount</th>\n","      <th>CreationDate</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>49995</th>\n","      <td>How can I send a file document to the printer ...</td>\n","      <td>&lt;p&gt;Here's the basic premise:&lt;/p&gt;\\n\\n&lt;p&gt;My user...</td>\n","      <td>&lt;c#&gt;&lt;winforms&gt;&lt;pdf&gt;&lt;.net-4.0&gt;&lt;printing&gt;</td>\n","      <td>6103705</td>\n","      <td>91</td>\n","      <td>215784</td>\n","      <td>0.0</td>\n","      <td>12</td>\n","      <td>2011-05-23 22:22:56</td>\n","    </tr>\n","    <tr>\n","      <th>49996</th>\n","      <td>CA1014 Mark 'some.dll' with CLSCompliant(true)...</td>\n","      <td>&lt;p&gt;When I run StyleCop, I got this error messa...</td>\n","      <td>&lt;visual-studio&gt;&lt;visual-studio-2010&gt;&lt;dll&gt;&lt;style...</td>\n","      <td>6103133</td>\n","      <td>17</td>\n","      <td>11024</td>\n","      <td>0.0</td>\n","      <td>2</td>\n","      <td>2011-05-23 21:15:51</td>\n","    </tr>\n","    <tr>\n","      <th>49997</th>\n","      <td>How to change a text file's name in C++?</td>\n","      <td>&lt;p&gt;I would like to change a &lt;code&gt;txt&lt;/code&gt; f...</td>\n","      <td>&lt;c++&gt;&lt;algorithm&gt;&lt;file&gt;&lt;directory&gt;&lt;file-rename&gt;</td>\n","      <td>6103036</td>\n","      <td>16</td>\n","      <td>37118</td>\n","      <td>0.0</td>\n","      <td>3</td>\n","      <td>2011-05-23 21:05:59</td>\n","    </tr>\n","    <tr>\n","      <th>49998</th>\n","      <td>php implode (101) with quotes</td>\n","      <td>&lt;p&gt;Imploding  a simple array &lt;/p&gt;\\n\\n&lt;p&gt;would ...</td>\n","      <td>&lt;php&gt;&lt;arrays&gt;&lt;string&gt;&lt;csv&gt;&lt;implode&gt;</td>\n","      <td>6102398</td>\n","      <td>156</td>\n","      <td>141141</td>\n","      <td>0.0</td>\n","      <td>16</td>\n","      <td>2011-05-23 20:06:35</td>\n","    </tr>\n","    <tr>\n","      <th>49999</th>\n","      <td>What characters are allowed in a iOS file name?</td>\n","      <td>&lt;p&gt;I'm looking for a way to make sure a string...</td>\n","      <td>&lt;ios&gt;&lt;file&gt;&lt;filenames&gt;&lt;character-encoding&gt;&lt;nsf...</td>\n","      <td>6102333</td>\n","      <td>29</td>\n","      <td>26085</td>\n","      <td>0.0</td>\n","      <td>10</td>\n","      <td>2011-05-23 20:00:57</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                   Title  \\\n","49995  How can I send a file document to the printer ...   \n","49996  CA1014 Mark 'some.dll' with CLSCompliant(true)...   \n","49997           How to change a text file's name in C++?   \n","49998                      php implode (101) with quotes   \n","49999    What characters are allowed in a iOS file name?   \n","\n","                                                    Body  \\\n","49995  <p>Here's the basic premise:</p>\\n\\n<p>My user...   \n","49996  <p>When I run StyleCop, I got this error messa...   \n","49997  <p>I would like to change a <code>txt</code> f...   \n","49998  <p>Imploding  a simple array </p>\\n\\n<p>would ...   \n","49999  <p>I'm looking for a way to make sure a string...   \n","\n","                                                    Tags       Id  Score  \\\n","49995            <c#><winforms><pdf><.net-4.0><printing>  6103705     91   \n","49996  <visual-studio><visual-studio-2010><dll><style...  6103133     17   \n","49997     <c++><algorithm><file><directory><file-rename>  6103036     16   \n","49998                <php><arrays><string><csv><implode>  6102398    156   \n","49999  <ios><file><filenames><character-encoding><nsf...  6102333     29   \n","\n","       ViewCount  FavoriteCount  AnswerCount         CreationDate  \n","49995     215784            0.0           12  2011-05-23 22:22:56  \n","49996      11024            0.0            2  2011-05-23 21:15:51  \n","49997      37118            0.0            3  2011-05-23 21:05:59  \n","49998     141141            0.0           16  2011-05-23 20:06:35  \n","49999      26085            0.0           10  2011-05-23 20:00:57  "]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["uniques :\n"]},{"data":{"text/plain":["Title            49999\n","Body             50000\n","Tags             48252\n","Id               50000\n","Score              761\n","ViewCount        36831\n","FavoriteCount        2\n","AnswerCount         64\n","CreationDate     49994\n","dtype: int64"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Doublons ?  0 \n","\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>column_name</th>\n","      <th>missing</th>\n","      <th>present</th>\n","      <th>percent_missing</th>\n","      <th>type</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Title</th>\n","      <td>Title</td>\n","      <td>0</td>\n","      <td>50000</td>\n","      <td>0.00</td>\n","      <td>object</td>\n","    </tr>\n","    <tr>\n","      <th>Body</th>\n","      <td>Body</td>\n","      <td>0</td>\n","      <td>50000</td>\n","      <td>0.00</td>\n","      <td>object</td>\n","    </tr>\n","    <tr>\n","      <th>Tags</th>\n","      <td>Tags</td>\n","      <td>0</td>\n","      <td>50000</td>\n","      <td>0.00</td>\n","      <td>object</td>\n","    </tr>\n","    <tr>\n","      <th>Id</th>\n","      <td>Id</td>\n","      <td>0</td>\n","      <td>50000</td>\n","      <td>0.00</td>\n","      <td>int64</td>\n","    </tr>\n","    <tr>\n","      <th>Score</th>\n","      <td>Score</td>\n","      <td>0</td>\n","      <td>50000</td>\n","      <td>0.00</td>\n","      <td>int64</td>\n","    </tr>\n","    <tr>\n","      <th>ViewCount</th>\n","      <td>ViewCount</td>\n","      <td>0</td>\n","      <td>50000</td>\n","      <td>0.00</td>\n","      <td>int64</td>\n","    </tr>\n","    <tr>\n","      <th>AnswerCount</th>\n","      <td>AnswerCount</td>\n","      <td>0</td>\n","      <td>50000</td>\n","      <td>0.00</td>\n","      <td>int64</td>\n","    </tr>\n","    <tr>\n","      <th>CreationDate</th>\n","      <td>CreationDate</td>\n","      <td>0</td>\n","      <td>50000</td>\n","      <td>0.00</td>\n","      <td>object</td>\n","    </tr>\n","    <tr>\n","      <th>FavoriteCount</th>\n","      <td>FavoriteCount</td>\n","      <td>1827</td>\n","      <td>48173</td>\n","      <td>3.65</td>\n","      <td>float64</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                 column_name  missing  present  percent_missing     type\n","Title                  Title        0    50000             0.00   object\n","Body                    Body        0    50000             0.00   object\n","Tags                    Tags        0    50000             0.00   object\n","Id                        Id        0    50000             0.00    int64\n","Score                  Score        0    50000             0.00    int64\n","ViewCount          ViewCount        0    50000             0.00    int64\n","AnswerCount      AnswerCount        0    50000             0.00    int64\n","CreationDate    CreationDate        0    50000             0.00   object\n","FavoriteCount  FavoriteCount     1827    48173             3.65  float64"]},"metadata":{},"output_type":"display_data"}],"source":["# Donnees compressées sinon on dépasse la limite /objet de Github (50Mb)\n","\n","# path to the zip file\n","zip_file_path = './../data/raw_data/QueryResults.zip'\n","\n","# directory where you want to extract the contents\n","extract_to_dir = './../data/raw_data'\n","\n","# Open the zip file\n","with ZipFile(zip_file_path, 'r') as zip_ref:\n","    # Extract all the contents into the specified directory\n","    zip_ref.extractall(extract_to_dir)\n","\n","# L'encodage est bien UTF-8 (vérifié en ouvrant le .csv ds vscode)\n","raw_data = pd.read_csv('./../data/raw_data/QueryResults.csv', sep=',')\n","\n","quick_look(raw_data)\n"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Id</th>\n","      <th>Score</th>\n","      <th>ViewCount</th>\n","      <th>FavoriteCount</th>\n","      <th>AnswerCount</th>\n","      <th>CreationDate</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>5.000000e+04</td>\n","      <td>50000.000000</td>\n","      <td>5.000000e+04</td>\n","      <td>48173.000000</td>\n","      <td>50000.000000</td>\n","      <td>50000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>2.878203e+07</td>\n","      <td>49.973980</td>\n","      <td>6.612881e+04</td>\n","      <td>0.000083</td>\n","      <td>5.384480</td>\n","      <td>2015-02-23 09:48:58.933900032</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>6.102333e+06</td>\n","      <td>11.000000</td>\n","      <td>1.000200e+04</td>\n","      <td>0.000000</td>\n","      <td>2.000000</td>\n","      <td>2011-05-23 20:00:57</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>1.413152e+07</td>\n","      <td>15.000000</td>\n","      <td>1.842050e+04</td>\n","      <td>0.000000</td>\n","      <td>3.000000</td>\n","      <td>2013-01-03 00:42:30.500000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>2.551682e+07</td>\n","      <td>24.000000</td>\n","      <td>3.210600e+04</td>\n","      <td>0.000000</td>\n","      <td>4.000000</td>\n","      <td>2014-08-26 23:41:22</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>4.133835e+07</td>\n","      <td>45.000000</td>\n","      <td>6.446725e+04</td>\n","      <td>0.000000</td>\n","      <td>6.000000</td>\n","      <td>2016-12-27 02:23:45</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>7.721511e+07</td>\n","      <td>27153.000000</td>\n","      <td>1.063924e+07</td>\n","      <td>1.000000</td>\n","      <td>87.000000</td>\n","      <td>2023-10-02 11:07:45</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>1.687404e+07</td>\n","      <td>168.429881</td>\n","      <td>1.424566e+05</td>\n","      <td>0.009112</td>\n","      <td>4.622519</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                 Id         Score     ViewCount  FavoriteCount   AnswerCount  \\\n","count  5.000000e+04  50000.000000  5.000000e+04   48173.000000  50000.000000   \n","mean   2.878203e+07     49.973980  6.612881e+04       0.000083      5.384480   \n","min    6.102333e+06     11.000000  1.000200e+04       0.000000      2.000000   \n","25%    1.413152e+07     15.000000  1.842050e+04       0.000000      3.000000   \n","50%    2.551682e+07     24.000000  3.210600e+04       0.000000      4.000000   \n","75%    4.133835e+07     45.000000  6.446725e+04       0.000000      6.000000   \n","max    7.721511e+07  27153.000000  1.063924e+07       1.000000     87.000000   \n","std    1.687404e+07    168.429881  1.424566e+05       0.009112      4.622519   \n","\n","                        CreationDate  \n","count                          50000  \n","mean   2015-02-23 09:48:58.933900032  \n","min              2011-05-23 20:00:57  \n","25%       2013-01-03 00:42:30.500000  \n","50%              2014-08-26 23:41:22  \n","75%              2016-12-27 02:23:45  \n","max              2023-10-02 11:07:45  \n","std                              NaN  "]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["# Pas de valeurs manquantes, à part FavoriteCount (pas important)\n","\n","# Seulement 2 titres identiques / 50 000 lignes\n","# id est bien une clé primaire\n","# body aussi, pas de questions en doublon (identiques)\n","\n","# On a environ 48 000 sets de tags différents, vérifier + tard combien de tags uniques\n","\n","# Les types semblent corrects,\n","# à part les dates bien sûr\n","\n","raw_data['CreationDate'] = pd.to_datetime(raw_data['CreationDate'])\n","# Après je pense qu'on n'utilisera jamais ces dates... Juste au cas où.\n","\n","raw_data.describe()\n","\n","# Avec nos critères (cf requete sql, fin ntbk2), il a fallu retourner jusqu'à mai 2011\n","# pour avoir 50 000 questions. On retrouve ici le favoriteCount très bas, proche de 0.\n","# On a une moyenne pour le score (environ 50), le nv de vues (66 000) et de réponses (>5)\n","# dans notre corpus.\n"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["raw_questions_tags = raw_data[['Title', 'Body', 'Tags']].copy()\n","\n","# Rename columns\n","raw_questions_tags = raw_questions_tags.rename(columns={'Title': 'title',\n","                                                        'Body': 'body',\n","                                                        'Tags': 'tags'})\n"]},{"cell_type":"markdown","metadata":{},"source":["### 2.2 Suppression des tags html\n"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["shape : (50000, 3)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>title</th>\n","      <th>body</th>\n","      <th>tags</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>ImportError: cannot import name 'url_decode' f...</td>\n","      <td>I am building a webapp using Flask. I imported...</td>\n","      <td>&lt;python&gt;&lt;flask&gt;&lt;importerror&gt;&lt;flask-login&gt;&lt;werk...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Compilation error after upgrading to JDK 21 - ...</td>\n","      <td>After upgrading to JDK 21, I have the followin...</td>\n","      <td>&lt;spring-boot&gt;&lt;compiler-errors&gt;&lt;upgrade&gt;&lt;lombok...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Differences between Langchain &amp; LlamaIndex</td>\n","      <td>I'm currently working on developing a chatbot ...</td>\n","      <td>&lt;chatbot&gt;&lt;openai-api&gt;&lt;langchain&gt;&lt;large-languag...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>session not created: This version of ChromeDri...</td>\n","      <td>I am running a Docker image from a Docker cont...</td>\n","      <td>&lt;python&gt;&lt;amazon-web-services&gt;&lt;docker&gt;&lt;google-c...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Spring security method cannot decide pattern i...</td>\n","      <td>When I try to run an application it fails to s...</td>\n","      <td>&lt;java&gt;&lt;spring-boot&gt;&lt;eclipse&gt;&lt;spring-security&gt;&lt;...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                               title  \\\n","0  ImportError: cannot import name 'url_decode' f...   \n","1  Compilation error after upgrading to JDK 21 - ...   \n","2         Differences between Langchain & LlamaIndex   \n","3  session not created: This version of ChromeDri...   \n","4  Spring security method cannot decide pattern i...   \n","\n","                                                body  \\\n","0  I am building a webapp using Flask. I imported...   \n","1  After upgrading to JDK 21, I have the followin...   \n","2  I'm currently working on developing a chatbot ...   \n","3  I am running a Docker image from a Docker cont...   \n","4  When I try to run an application it fails to s...   \n","\n","                                                tags  \n","0  <python><flask><importerror><flask-login><werk...  \n","1  <spring-boot><compiler-errors><upgrade><lombok...  \n","2  <chatbot><openai-api><langchain><large-languag...  \n","3  <python><amazon-web-services><docker><google-c...  \n","4  <java><spring-boot><eclipse><spring-security><...  "]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>title</th>\n","      <th>body</th>\n","      <th>tags</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>49995</th>\n","      <td>How can I send a file document to the printer ...</td>\n","      <td>Here's the basic premise:\\nMy user clicks some...</td>\n","      <td>&lt;c#&gt;&lt;winforms&gt;&lt;pdf&gt;&lt;.net-4.0&gt;&lt;printing&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>49996</th>\n","      <td>CA1014 Mark 'some.dll' with CLSCompliant(true)...</td>\n","      <td>When I run StyleCop, I got this error message ...</td>\n","      <td>&lt;visual-studio&gt;&lt;visual-studio-2010&gt;&lt;dll&gt;&lt;style...</td>\n","    </tr>\n","    <tr>\n","      <th>49997</th>\n","      <td>How to change a text file's name in C++?</td>\n","      <td>I would like to change a txt file's name, but ...</td>\n","      <td>&lt;c++&gt;&lt;algorithm&gt;&lt;file&gt;&lt;directory&gt;&lt;file-rename&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>49998</th>\n","      <td>php implode (101) with quotes</td>\n","      <td>Imploding  a simple array \\nwould look like th...</td>\n","      <td>&lt;php&gt;&lt;arrays&gt;&lt;string&gt;&lt;csv&gt;&lt;implode&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>49999</th>\n","      <td>What characters are allowed in a iOS file name?</td>\n","      <td>I'm looking for a way to make sure a string ca...</td>\n","      <td>&lt;ios&gt;&lt;file&gt;&lt;filenames&gt;&lt;character-encoding&gt;&lt;nsf...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                   title  \\\n","49995  How can I send a file document to the printer ...   \n","49996  CA1014 Mark 'some.dll' with CLSCompliant(true)...   \n","49997           How to change a text file's name in C++?   \n","49998                      php implode (101) with quotes   \n","49999    What characters are allowed in a iOS file name?   \n","\n","                                                    body  \\\n","49995  Here's the basic premise:\\nMy user clicks some...   \n","49996  When I run StyleCop, I got this error message ...   \n","49997  I would like to change a txt file's name, but ...   \n","49998  Imploding  a simple array \\nwould look like th...   \n","49999  I'm looking for a way to make sure a string ca...   \n","\n","                                                    tags  \n","49995            <c#><winforms><pdf><.net-4.0><printing>  \n","49996  <visual-studio><visual-studio-2010><dll><style...  \n","49997     <c++><algorithm><file><directory><file-rename>  \n","49998                <php><arrays><string><csv><implode>  \n","49999  <ios><file><filenames><character-encoding><nsf...  "]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["uniques :\n"]},{"data":{"text/plain":["title    49999\n","body     50000\n","tags     48252\n","dtype: int64"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Doublons ?  0 \n","\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>column_name</th>\n","      <th>missing</th>\n","      <th>present</th>\n","      <th>percent_missing</th>\n","      <th>type</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>title</th>\n","      <td>title</td>\n","      <td>0</td>\n","      <td>50000</td>\n","      <td>0.0</td>\n","      <td>object</td>\n","    </tr>\n","    <tr>\n","      <th>body</th>\n","      <td>body</td>\n","      <td>0</td>\n","      <td>50000</td>\n","      <td>0.0</td>\n","      <td>object</td>\n","    </tr>\n","    <tr>\n","      <th>tags</th>\n","      <td>tags</td>\n","      <td>0</td>\n","      <td>50000</td>\n","      <td>0.0</td>\n","      <td>object</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      column_name  missing  present  percent_missing    type\n","title       title        0    50000              0.0  object\n","body         body        0    50000              0.0  object\n","tags         tags        0    50000              0.0  object"]},"metadata":{},"output_type":"display_data"}],"source":["raw_questions_tags['body'] = raw_questions_tags['body'].parallel_apply(\n","    lambda x: BeautifulSoup(x, 'html.parser').get_text())\n","\n","quick_look(raw_questions_tags)\n","\n","# environ 25s sans pandarallel -> 5-6s sur 6 cores\n","# pandarallel adopté !\n"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_407073/1392450844.py:5: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n","  lambda x: BeautifulSoup(x, 'html.parser').get_text())\n","/tmp/ipykernel_407073/1392450844.py:5: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n","  lambda x: BeautifulSoup(x, 'html.parser').get_text())\n","/tmp/ipykernel_407073/1392450844.py:5: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n","  lambda x: BeautifulSoup(x, 'html.parser').get_text())\n","/tmp/ipykernel_407073/1392450844.py:5: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n","  lambda x: BeautifulSoup(x, 'html.parser').get_text())\n","/tmp/ipykernel_407073/1392450844.py:5: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n","  lambda x: BeautifulSoup(x, 'html.parser').get_text())\n","/tmp/ipykernel_407073/1392450844.py:5: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n","  lambda x: BeautifulSoup(x, 'html.parser').get_text())\n"]}],"source":["# Je ne vois pas de balises dans les titres\n","# mais j'avoue je n'ai pas lu les 50 000 titres, donc au cas où :\n","\n","raw_questions_tags['title'] = raw_questions_tags['title'].parallel_apply(\n","    lambda x: BeautifulSoup(x, 'html.parser').get_text())\n","\n","# Le warning n'a pas d'importance ici : du texte qui ne contient pas de tags html\n","# n'est pas modifié par BeautifulSoup.get_text()\n","\n","# J'hésitais à concaténer title + body ici, mais on testera les modeles seulment sur les titres\n","# pour avoir une baseline. On va donc conserver les 2 features, et les traiter en parallèle.\n"]},{"cell_type":"markdown","metadata":{},"source":["### 2.3 Tokenisation, majuscules, ponctuation\n"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["# Après qq tests, le + efficace ici semble d'appliquer d'abord la fonction word_tokenize(),\n","# qui gère mieux beaucoup de spécificités de l'anglais (ex: contractions),\n","# puis le RegexpTokenizer pour 'découper' ensuite les adresses mails, URLS, etc...\n","# Il y aurait d'autres stratégies possibles, par exemples utiliser d'abord le module contractions.\n","\n","def preprocess_1_tokenize(text, remove_punct=True):\n","    \"\"\"\n","    Clean input text (lower, strip spaces), Tokenize, Remove punctuation.\n","\n","    Parameters:\n","    - text (str): Input text to tokenize.\n","    - remove_punct (bool): filter punctuation marks.\n","\n","    Returns:\n","    - list: List of tokens.\n","    \"\"\"\n","    # Nettoyage des majuscules et des espaces\n","    text = text.lower().strip()\n","    try:\n","        tokens = nltk.word_tokenize(text)\n","        tokenizer = nltk.RegexpTokenizer(r'\\w+')\n","        tokens = tokenizer.tokenize(\" \".join(tokens))  # Apply RegexpTokenizer to the entire list\n","\n","        if remove_punct:\n","            # Remove punctuation (make sure)\n","            tokens = [token for token in tokens if token not in string.punctuation]\n","\n","    except Exception as e:\n","        print(f\"Error in tokenization: {e}\")\n","        return []\n","\n","    return tokens\n","\n","\n","raw_questions_tags['body_tokens'] = raw_questions_tags['body'].parallel_apply(\n","    lambda x: preprocess_1_tokenize(x))\n"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["# Idem for the 'title' column\n","raw_questions_tags['title_tokens'] = raw_questions_tags['title'].parallel_apply(\n","    lambda x: preprocess_1_tokenize(x))\n"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"ename":"TypeError","evalue":"unhashable type: 'list'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32m/home/ubuntu/Bureau/OC/Projet5_oudelet_kevin/notebooks/Oudelet_Kevin_1_notebook_exploration_271123.ipynb Cell 20\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/ubuntu/Bureau/OC/Projet5_oudelet_kevin/notebooks/Oudelet_Kevin_1_notebook_exploration_271123.ipynb#Y115sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m raw_questions_tags[\u001b[39m'\u001b[39m\u001b[39mnb_tokens\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mset\u001b[39m(raw_questions_tags[\u001b[39m'\u001b[39m\u001b[39mtitle_tokens\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ubuntu/Bureau/OC/Projet5_oudelet_kevin/notebooks/Oudelet_Kevin_1_notebook_exploration_271123.ipynb#Y115sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m                                            \u001b[39m+\u001b[39m raw_questions_tags[\u001b[39m'\u001b[39m\u001b[39mbody_tokens\u001b[39m\u001b[39m'\u001b[39m]))\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ubuntu/Bureau/OC/Projet5_oudelet_kevin/notebooks/Oudelet_Kevin_1_notebook_exploration_271123.ipynb#Y115sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m display(raw_questions_tags)\n","\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"]}],"source":["raw_questions_tags['nb_tokens'] = len(set(raw_questions_tags['title_tokens']\n","                                           + raw_questions_tags['body_tokens']))\n","\n","display(raw_questions_tags)\n"]},{"cell_type":"markdown","metadata":{},"source":["### 2.4 tokens uniques\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def preprocess_2_keep_uniques_only(liste_tokens):\n","    seen_tokens = set()\n","    unique_tokens = []\n","\n","    for token in liste_tokens:\n","        if token not in seen_tokens:\n","            seen_tokens.add(token)\n","            unique_tokens.append(token)\n","\n","    return unique_tokens\n","\n","# Apply the preprocessing function to body\n","raw_questions_tags['body_tokens_uniques'] = raw_questions_tags['body_tokens'].parallel_apply(preprocess_2_keep_uniques_only)\n","print('Done')\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# and title\n","raw_questions_tags['title_tokens_uniques'] = raw_questions_tags['title_tokens'].parallel_apply(preprocess_2_keep_uniques_only)\n","print('Done')\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["raw_questions_tags['nb_tokens_uniques'] = len(set((raw_questions_tags['title_tokens_uniques'].parallel_apply(\n","    lambda x: preprocess_1_tokenize(x)) + raw_questions_tags['body_tokens_uniques'].parallel_apply(\n","    lambda x: preprocess_1_tokenize(x)))))\n","\n","display(raw_questions_tags)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fig, ax = plt.subplots(figsize=(10, 6))\n","\n","# Plotting 'nb_mots'\n","raw_questions_tags['nb_tokens'].hist(density=False, bins=50, ax=ax, color='#7cf', alpha=0.6, label='nb_mots')\n","\n","# Plotting 'nb_mots_uniques'\n","raw_questions_tags['nb_tokens_uniques'].hist(density=False, bins=50, ax=ax, label='nb_mots_uniques')\n","\n","plt.title('Vocabulaire', pad=20, fontsize=18)\n","plt.xticks(fontsize=12)\n","plt.yticks(fontsize=12)\n","\n","ax.legend()\n","\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["graphs_analyse_uni(raw_questions_tags, 'nb_tokens', bins=50, r=2, density=True)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["graphs_analyse_uni(raw_questions_tags, 'nb_tokens_uniques', bins=50, r=2, density=True)\n","\n","# moyenne divisée par 2\n"]},{"cell_type":"markdown","metadata":{},"source":["### 2.5 Fréquence des mots\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Extract tokens from the 'tokens_uniques' column\n","all_tokens = set([token for tokens_list in raw_questions_tags['title_tokens_uniques'] for token in tokens_list]\n","                 + [token for tokens_list in raw_questions_tags['body_tokens_uniques'] for token in tokens_list])\n","\n","print (len(all_tokens))\n","\n","# Calculate token frequencies using a loop\n","# J'ai découvert plus tard la fonction FreqDist() de nltk, qui fait la mm chose\n","token_frequencies_dict = {}\n","for token in all_tokens:\n","    token_frequencies_dict[token] = token_frequencies_dict.get(token, 0) + 1\n","\n","# Display the first 50 items in the token frequencies dictionary\n","for token, frequency in list(token_frequencies_dict.items())[:50]:\n","    print(f\"{token}: {frequency}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Sort the dictionary items by values in descending order\n","sorted_token_frequencies = dict(sorted(token_frequencies_dict.items(), key=lambda item: item[1], reverse=True))\n","\n","# Display the first 50 items in the token frequencies dictionary\n","for token, frequency in list(sorted_token_frequencies.items())[:50]:\n","    print(f\"{token}: {frequency}\")\n","\n","# La plupart de ces mots appartiennent probablement à la liste des stopwords\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Visualisons\n","\n","df_freq = pd.DataFrame(list(token_frequencies_dict.items()), columns=['Token', 'Frequency'])\n","\n","# Sort the DataFrame by frequency in descending order\n","df_freq = df_freq.sort_values(by='Frequency', ascending=False)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Plot the distribution using Plotly\n","\n","df = df_freq[:200]\n","\n","fig = px.bar(df, x='Token', y='Frequency', labels={'Token': 'Token', 'Frequency': 'Frequency'},\n","             title='Token Frequency Distribution', text='Frequency')\n","fig.update_xaxes(tickangle=45, tickmode='array', tickvals=df.index, ticktext=df['Token'])\n","\n","# Show the plot\n","fig.show()\n"]},{"cell_type":"markdown","metadata":{},"source":["### 2.6 Stopwords\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Get a set of English stop words from NLTK\n","stopwords = set(nltk.corpus.stopwords.words('english'))\n","\n","# Update the set with additional stop words if needed (most frequent ?)\n","# stopwords.update(['additional', 'stop', 'words'])\n","\n","important_tokens = [token for token in all_tokens if token not in stopwords]\n","print(len(important_tokens))\n","\n","# Display the first 50 items in the token frequencies dictionary\n","for token, frequency in list(sorted_token_frequencies.items())[:200]:\n","    if token in important_tokens:\n","        print(f\"{token}: {frequency}\")\n","\n","# Il y a encore bcp de mots très communs. Pas sûr où placer le seuil\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def preprocess_text_3(liste_tokens):\n","    # ajouter /frequence ici ?\n","\n","    filtered_list = [token for token in liste_tokens if token not in stopwords]\n","\n","    return filtered_list\n","\n","# Apply the preprocessing function\n","raw_questions_tags['tokens_uniques_no_stopwords'] = raw_questions_tags['tokens_uniques_regex'].parallel_apply(preprocess_text_3)\n","print('Done')\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["raw_questions_tags['nb_tokens_uniques_no_stopwords'] = raw_questions_tags['tokens_uniques_no_stopwords'].parallel_apply(len)\n","print('Done')\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fig, ax = plt.subplots(figsize=(10, 6))\n","\n","# Plotting 'nb_mots'\n","raw_questions_tags['nb_mots_regex'].hist(density=False, bins=50, ax=ax, color='#7cf', alpha=0.6, label='nb_mots')\n","\n","# Plotting 'nb_mots_uniques'\n","raw_questions_tags['nb_mots_uniques_regex'].hist(density=False, bins=50, ax=ax, label='nb_mots_uniques')\n","\n","# Plotting 'nb_mots_uniques non stopwords'\n","raw_questions_tags['nb_tokens_uniques_no_stopwords'].hist(density=False, bins=50, color='#fc3', ax=ax,\n","                                                          label='nb_mots_uniques hors stopwords')\n","\n","plt.title('Vocabulaire', pad=20, fontsize=18)\n","plt.xticks(fontsize=12)\n","plt.yticks(fontsize=12)\n","\n","ax.legend()\n","\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{},"source":["### 2.7 Lemmatization + filtrage syntaxique\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Lemmatization tends to be more accurate but can be slower than stemming.\n","# On a utilisé le stemming en français, dans le cours openclassrooms\n","# Utilisons la lemmatisation ici, + appropriée pour notre objectif\n","# (extraire le sens important, le thème, pour proposer des tags)\n","# On peut aussi profiter de l'analyse grammaticale (POS) pour\n","# conserver uniquement les mots les plus \"importants\" dans la phrase, les noms et les verbes.\n","\n","def lemmatize_tokens(tokens, filter=True):\n","    lemmatizer = WordNetLemmatizer()\n","\n","    def get_wordnet_pos(pos_tag):\n","        if pos_tag.startswith('J'):\n","            return wordnet.ADJ\n","        elif pos_tag.startswith('R'):\n","            return wordnet.ADV\n","        elif pos_tag.startswith('V'):\n","            return wordnet.VERB\n","        elif pos_tag.startswith('N'):\n","            return wordnet.NOUN\n","        else:\n","            return wordnet.NOUN  # Default to noun if the part of speech is not recognized\n","\n","    # Get part of speech for each token\n","    pos_tags = nltk.pos_tag(tokens)\n","\n","    # Lemmatize each token\n","    lemmatized_tokens = []\n","    for token, pos_tag in pos_tags:\n","        if filter and pos_tag.startswith(('J', 'R')):\n","            # Exclude adjectives (J) and adverbs (R) if filter is enabled\n","            lemmatized_tokens.append(\" \")\n","        else:\n","            lemmatized_tokens.append(lemmatizer.lemmatize(token, pos=get_wordnet_pos(pos_tag)))\n","\n","    return lemmatized_tokens\n","\n","# Assuming raw_questions_tags is a DataFrame with a column 'tokens_uniques_no_stopwords'\n","# Replace 'tokens_uniques_no_stopwords' with the actual column name if needed\n","raw_questions_tags['lemms'] = raw_questions_tags['tokens_uniques_no_stopwords'].parallel_apply(lemmatize_tokens)\n","print('Done')\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# garde seulmt les lemmes uniques\n","raw_questions_tags['lemms_uniques'] = raw_questions_tags['lemms'].parallel_apply(preprocess_2_keep_uniques_only)\n","print('Done')\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["raw_questions_tags['nb_lemms'] = raw_questions_tags['lemms'].parallel_apply(len)\n","raw_questions_tags['nb_lemms_uniques'] = raw_questions_tags['lemms_uniques'].parallel_apply(len)\n","print('Done')\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fig, ax = plt.subplots(figsize=(10, 6))\n","\n","# Plotting 'nb_mots'\n","raw_questions_tags['nb_mots_regex'].hist(density=False, bins=50, ax=ax, color='#7cf', alpha=0.6, label='nb_mots')\n","\n","# Plotting 'nb_mots_uniques'\n","raw_questions_tags['nb_mots_uniques_regex'].hist(density=False, bins=50, ax=ax, label='nb_mots_uniques')\n","\n","# Plotting 'nb_mots_uniques non stopwords'\n","raw_questions_tags['nb_tokens_uniques_no_stopwords'].hist(density=False, bins=50, color='#fc3', ax=ax,\n","                                                          label='nb_mots_uniques hors stopwords')\n","# Plotting 'lemms'\n","raw_questions_tags['nb_lemms_uniques'].hist(density=False, bins=50, color='#f81', ax=ax,\n","                                                          label='nb_lemms_uniques')\n","\n","plt.title('Vocabulaire', pad=20, fontsize=18)\n","plt.xticks(fontsize=12)\n","plt.yticks(fontsize=12)\n","\n","ax.legend()\n","\n","plt.show()\n","\n","# On voit une petite différence\n"]},{"cell_type":"markdown","metadata":{},"source":["### 2.8 Explorer le corpus obtenu\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Affichons 20 questions au hasard (+ les tags)\n","\n","# display(raw_questions_tags[['questions', 'lemms']].sample(20))\n","\n","display(raw_questions_tags.sample(20))\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Pistes restantes\n","\n","# Handling Numeric Values:\n","# Decide whether to keep or remove numeric values based on their relevance to your prediction task.\n","# Rare Words: Consider removing or replacing rare words to reduce the dimensionality of your data.\n","# Contractions: Expand contractions to ensure consistency (e.g., \"don't\" to \"do not\").\n","# URLs and Email Addresses\n","\n","# Pour les tags\n","# Label Encoding: If your tags are categorical, encode them into numerical labels.\n"]},{"cell_type":"markdown","metadata":{},"source":["## 3 Target\n"]},{"cell_type":"markdown","metadata":{},"source":["### 3.1 Preprocessing\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def preprocess_tags(tags_string):\n","    # just in case\n","    tags_string = tags_string.lower()\n","    # Split tags by '><'\n","    tags_list = tags_string.split('><')\n","\n","    # Remove angle brackets from the first and last tag\n","    tags_list[0] = tags_list[0][1:]\n","    tags_list[-1] = tags_list[-1][:-1]\n","\n","    return tags_list\n","\n","# Apply the preprocessing function to the 'tags' column\n","raw_questions_tags['tags_list'] = raw_questions_tags['tags'].apply(preprocess_tags)\n","\n","display(raw_questions_tags[['tags', 'tags_list']].head(10))\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["all_tags = [tag for tags in raw_questions_tags['tags_list'] for tag in tags]\n","print(len(all_tags))\n","\n","# Au cas où il y aurait des doublons ds les tags\n","raw_questions_tags['tags_uniques'] = raw_questions_tags['tags'].apply(preprocess_2_keep_uniques_only)\n","\n","# Fréquence\n","# Factoriser\n","tag_frequencies_dict = {}\n","for tag in all_tags:\n","    tag_frequencies_dict[tag] = tag_frequencies_dict.get(tag, 0) + 1\n","\n","# Sort the dictionary items by values in descending order\n","sorted_tag_frequencies = dict(sorted(tag_frequencies_dict.items(), key=lambda item: item[1], reverse=True))\n","\n","# Display the first 50 items in the tag frequencies dictionary\n","for tag, frequency in list(sorted_tag_frequencies.items())[:50]:\n","    print(f\"{tag}: {frequency}\")\n","\n","# 250 000 tags (différents) !\n","# Ca repond a la question : est-ce qu'un humain pourrait facilement faire cette tache.\n","# Il faudrait déjà connaitre ts les tags possibles... Pas évident.\n","\n","# Le tag le plus présent est python\n","# Est-ce qu'il y a plus de codeurs en python qu'en javascript ?\n","# Peut-être. Pas sûr.\n","# Est-ce qu'on va sur stack overflow plus souvent quand on fait du python ?\n","# Je dirais que oui. Il y a tjs de nveaux modules à découvrir en python !\n","\n","# Classement intéressant !\n"]},{"cell_type":"markdown","metadata":{},"source":["### 3.2 Frequences des tags\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Extract tags and frequencies\n","tags = list(sorted_tag_frequencies.keys())\n","frequencies = list(sorted_tag_frequencies.values())\n","\n","# Plot\n","plt.figure(figsize=(12, 6))\n","plt.bar(tags[:100], frequencies[:100], color='skyblue')\n","plt.xlabel('Tags')\n","plt.ylabel('Frequency')\n","plt.title('Top 50 Tag Frequencies')\n","plt.xticks(rotation=90, ha='right', fontsize=8)  # Rotate x-axis labels for better readability\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{},"source":["### 3.3 Les 20 tags les + frequents\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# + d'un tiers des question concernent python, js ou java.\n","\n","# Faisons un top 20\n","df_freq = pd.DataFrame({'Tag': tags, 'Frequency': frequencies})\n","\n","# Display the DataFrame\n","display(df_freq.head())\n","\n","# plot a pie\n","colors = generate_random_pastel_colors(20)\n","\n","fig, ax = plt.subplots(figsize=(10, 10))\n","\n","patches, texts, autotexts = plt.pie(x=df_freq['Frequency'][:20], autopct='%1.1f%%',\n","    startangle=-30, labels=df_freq['Tag'][:20], textprops={'fontsize':11, 'color':'#000'},\n","    labeldistance=1.25, pctdistance=0.85, colors=colors)\n","\n","plt.title(\n","label='20 most frequent Tags',\n","fontdict={\"fontsize\":17},\n","pad=20\n",")\n","\n","for text in texts:\n","    # text.set_fontweight('bold')\n","    text.set_horizontalalignment('center')\n","\n","# Customize percent labels\n","for autotext in autotexts:\n","    autotext.set_horizontalalignment('center')\n","    autotext.set_fontstyle('italic')\n","    autotext.set_fontsize('10')\n","\n","#draw circle\n","centre_circle = plt.Circle((0,0),0.7,fc='white')\n","fig = plt.gcf()\n","fig.gca().add_artist(centre_circle)\n","\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{},"source":["### 3.4 Tags rares\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# A l'inverse, certains tags sont rares\n","\n","# Count tags with frequency less than 10\n","tags_below_10 = sum(1 for frequency in sorted_tag_frequencies.values() if frequency < 10)\n","print(tags_below_10)\n","\n","# voire tres rares\n","# tags hapax (1 seule occurence)\n","\n","# Count tags with frequency less than 2\n","tags_below_2 = sum(1 for frequency in sorted_tag_frequencies.values() if frequency < 2)\n","print(tags_below_2)\n"]},{"cell_type":"markdown","metadata":{},"source":["### 3.5 wordcloud\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["cloud = WordCloud(background_color='white',\n","                  stopwords=[],\n","                  max_words=50).generate(\" \".join(all_tags))\n","plt.imshow(cloud)\n","plt.axis('off')\n","plt.show()\n","\n","# Pourquoi python tout petit ?? C le tag le + frequent !\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# analyse multi ici\n"]},{"cell_type":"markdown","metadata":{},"source":["## Normalisation\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":5}
